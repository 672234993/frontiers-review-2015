{
 "metadata": {
  "name": "frontiers-nb-2015"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "The largest challenge facing the usage of metagenomic approaches in microbiology is the need to extend traditional microbiology training to include metagenomic or sequencing data analysis. Sean Eddy (a compuational biologist at the Howard Hughes Medical Institute) nicely describes the impacts of high throughput sequencing on biology and its training in his keynote address (http://cryptogenomicon.org/2014/11/01/high-throughput-sequencing-for-neuroscience/#more-858).\n",
      "\n",
      "To facilitate the barriers to microbiologists for metagenomic assembly, we have complemented this review with a tutorial of how to estimate the abundance of reference sequences (e.g., genes, contigs, etc.) in a metagenome.  We include approaches that include using references that are both (i) available genome references or (ii) assembled from the metagenome. In general, to complete this tutorial and most metagenomic assembly, one would need:\n",
      "\n",
      "* Access to a server.  Most metagenomic assembly will require more memory than most researchers will have on their personal computers.  In this tutorial, we will provide training on the publicly accessible Amazon EC2 instances which can be rented by anyone with a registered account.\n",
      "* Access to a metagenomic dataset.  We have selected the usage of the HMP Mock Community WGS dataset (http://www.hmpdacc.org/HMMC/) for this tutorial given its availability, practical size, and availability of reference genomes.  This dataset represents a mock metagenome of 22 known organisms for which DNA was extracted from cultured isolates, combined, and sequenced.\n",
      "* Software for assembly, read mapping, and annotation.  We will demonstrate the installation of this software on an Ubuntu-based server.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 0.  Getting on the same page.\n",
      "\n",
      "The first step in this tutorial is to provide all users access to a server for which these instructions can be used, regardless of what computer you may be on. To do this, we'll be using cloud computing. More specifically, Amazon Web Services Elastic Compute Cloud.\n",
      "To rent compute time off of Amazon Web Services, you'll have to sign up and pay with a credit card. The cost is pretty manageable, http://aws.amazon.com/ec2/pricing/. You should be able to complete this tutorial in less than four hours, which comes out to < $1.\n",
      "\n",
      "Once you are signed up for Amazon Web Services, you need to follow some instructions to launch a cloud \"instance\" or server. For this tutorial, we suggest you use the instructions from the Data Science Toolbox, http://datasciencetoolbox.org/#bundles. A couple things to note prior to running through those instructions:\n",
      "\n",
      "* Choose the \"in the cloud\" instructions\n",
      "* You can choose any AMI but we suggest US EAST, ami-d1737bb8\n",
      "* When you configure your instance, choose the m3.large instance\n",
      "* Do not forget to \"Add rule\" as described in the directions in Data Science Toolbox Step 2:  Add a \"custom TCP rule\" for port \"8888\" and source \"Anywhere\".\n",
      "* Complete the Data Science Instructions through Step 4.  Once you get to Step 5, refer below.\n",
      "\n",
      "If you have trouble logging into your instance and you are on a Mac or Linux OS: \n",
      "\n",
      "* Check to see that you changed permissions on your key file (the one that ends in *.pem)\n",
      "* Make sure you run the ssh command to log into the instance in the same directory as your security file or specify the location of that file\n",
      "\n",
      "Once you are logged into the instance, for example, you've successfully run the following command (except you'll have your own security file uniquely named and your own special EC2 address):\n",
      "\n",
      "    $ ssh -i MyKeyPair.pem ubuntu@ec2-XX-XX-XX-XXX.compute-1.amazonaws.com\n",
      "\n",
      "And you now have a command line that looks like:\n",
      "\n",
      "    ubuntu@ip-10-181-106-120:\n",
      "\n",
      "You need to do a couple things to get this tutorial running:\n",
      "\n",
      "Copy and paste the following commands one by one into your command line and press ENTER after each one:\n",
      "\n",
      "    cd /mnt\n",
      "    \n",
      "    sudo git clone https://github.com/germs-lab/frontiers-review-2015.git\n",
      "\n",
      "\n",
      "Next, copy and paste the following command and enter a notebook password of your choice when prompted:\n",
      "\n",
      "    dst setup base\n",
      "\n",
      "Then, copy and paste this command:\n",
      "\n",
      "    sudo ipython notebook --profile=dst --notebook-dir=/mnt/frontiers-review-2015\n",
      "\n",
      "This will start up an IPython Notebook for this tutorial.  Leave the terminal screen open and find your internet browser, preferablly Google Chrome.  You'll also need the address for your EC2 instance public DNS that you used to log in above \"e.g., ec2-XX-XX-XX-XXX\".  If you don't know it, you can always check on your AWS EC2 dashboard (see running instances) here, https://console.aws.amazon.com/ec2/v2/.\n",
      "\n",
      "On your web browser, navigate to https://ec2-XX-XX-XX-XXX:8888 (except with your specific EC2 public DNS).  Almost all web browsers will have a message that says you're heading to an unsafe place.  Don't be alarmed.  On Chrome, you can hit the \"Advanced\" options link and hit \"Proceed anyways\".  Then, type in the password (password is the one you chose above), and voila, you'll see a notebook that contains this text called \"frontiers-nb-2015\".\n",
      "\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. How to use this IPython Notebook\n",
      "IPython notebooks are very useful to collaboratively train bioinformatics. These notebooks have recently been featured in Nature News (http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261 and http://www.nature.com/news/programming-pick-up-python-1.16833)\n",
      "\n",
      "In using these notebooks, there are a few imporant things to note. There are two types of content in this tutorial: text and code. This content is placed in this notebook as \"cells\". If you click around on this page, you'll see different cells highlighted. To execute each cell (regardless of content), you hit on your keyboard SHIFT+ENTER. If the cell contains text, the content will be displayed directly. If the cell contains code, the code will then execute. Also, you can execute all cells in the notebook by going to the Cell tab where \"File, Edit, View, Insert, Cell...\" are in the top left of this webpage and selecting _Run all_."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.  Download the tutorial dataset.\n",
      "\n",
      "We will begin this tutorial by downloading the HMP mock metagenome from the NCBI Short Read Archives (SRA).  Many public metagenomes are stored as SRA files in the NCBI. The easiest way to get these SRA files is to use a special set of tools called the *sratoolkit*.  If you have your dataset SRA run ID (in this case SRR172903), you can download the dataset and convert it to the standard \"fasta\" or \"fastq\" sequencing format is to use a special program to convert the file.  \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wget http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.4.5-2/sratoolkit.2.4.5-2-ubuntu64.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--2015-06-15 15:54:27--  http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.4.5-2/sratoolkit.2.4.5-2-ubuntu64.tar.gz\r\n",
        "Resolving ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)... 130.14.250.7, 2607:f220:41e:250::11\r\n",
        "Connecting to ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)|130.14.250.7|:80... connected.\r\n",
        "HTTP request sent, awaiting response... 200 OK\r\n",
        "Length: 62432226 (60M) [application/x-gzip]\r\n",
        "Saving to: \u2018sratoolkit.2.4.5-2-ubuntu64.tar.gz\u2019\r\n",
        "\r\n",
        "\r",
        " 0% [                                       ] 0           --.-K/s              "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 14,207,592  67.7MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "58% [=====================>                 ] 36,598,472  87.2MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "94% [====================================>  ] 59,282,384  94.2MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100%[======================================>] 62,432,226  94.7MB/s   in 0.6s   \r\n",
        "\r\n",
        "2015-06-15 15:54:28 (94.7 MB/s) - \u2018sratoolkit.2.4.5-2-ubuntu64.tar.gz\u2019 saved [62432226/62432226]\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tar -xvf sratoolkit.2.4.5-2-ubuntu64.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/README\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/README-blastn\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/README-vdb-config\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/ncbi/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/ncbi/default.kfg\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/ncbi/vdb-copy.kfg\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/align-info\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/align-info.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/align-info.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/bam-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/bam-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/bam-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/blastn_vdb\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/blastn_vdb.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/blastn_vdb.2.2.30-2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/cache-mgr\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cache-mgr.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cache-mgr.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cg-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cg-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cg-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/helicos-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/helicos-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/helicos-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/kar\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kar.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kar.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/kdbmeta\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kdbmeta.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kdbmeta.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/latf-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/latf-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/latf-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/pacbio-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/pacbio-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/pacbio-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/prefetch\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/prefetch.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/prefetch.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/rcexplain\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/rcexplain.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/rcexplain.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/remote-fuser\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/remote-fuser.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/remote-fuser.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sam-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sam-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sam-dump.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-kar\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-kar.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-kar.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-pileup\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-pileup.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-pileup.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-sort\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-sort.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-sort.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-stat\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-stat.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-stat.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srapath\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srapath.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srapath.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/srf-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srf-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srf-load.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/tblastn_vdb\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/tblastn_vdb.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/tblastn_vdb.2.2.30-2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/test-sra\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/test-sra.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/test-sra.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-config\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-config.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-config.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-copy\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-copy.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-copy.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-decrypt\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-decrypt.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-decrypt.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-dump.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-encrypt\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-encrypt.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-encrypt.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-lock\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-lock.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-lock.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-passwd\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-passwd.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-passwd.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-unlock\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-unlock.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-unlock.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-validate\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-validate.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-validate.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/base-stats.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/dump-reference.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/gene-lookup.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/mismatch-stats.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/quality-stats.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/simplefastq.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/splitfastq.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/align.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/mate-cache.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/qstat.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/refseq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/seq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/insdc.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/seq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/sra.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/clip.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/ncbi.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/pnbrdb.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/seq-graph.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/seq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/spotname.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/sra.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/stats.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/varloc.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/wgs-contig.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/454.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/abi.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/helicos.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/illumina.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/ion-torrent.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/pacbio.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/pevents.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/vdb/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/vdb/built-in.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/vdb/vdb.vschema\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that we now have a file containing the software with the \"ls\" command.  You'll also see this notebook in the list of files in the present location we are working in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "assemstats3.py\t\t\t     kmer-count-plot.py\r\n",
        "bowtie.sh\t\t\t     LICENSE.md\r\n",
        "fetch-genomes-fasta.py\t\t     ncbi_acc.txt\r\n",
        "frontiers-nb-2015.ipynb\t\t     README.md\r\n",
        "frontiers-nb-2015-with-output.ipynb  remove_output.py\r\n",
        "install-megahit.sh\t\t     sratoolkit.2.4.5-2-ubuntu64\r\n",
        "ipython_notebook_config.py\t     sratoolkit.2.4.5-2-ubuntu64.tar.gz\r\n",
        "khmer\t\t\t\t     unique-kmers.py\r\n",
        "khmer-install.sh\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll use the installed sratoolkit program to download the HMP mock dataset in \"fastq\" format. (This takes a minute or two.  You'll find that patience is require for working with metagenomes.  The nice thing about working in the cloud is that you are \"renting\" the computational power so it is not using your personal computer's memory -- freeing it up for things you can do while waiting.  You'll note that you can see that \"Kernel busy\" will be shown on the top-right corner of the screen below \"Logout\" button.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump SRR172903"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Read 7932819 spots for SRR172903\r\n",
        "Written 7932819 spots for SRR172903\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3.  Quality control\n",
      "\n",
      "There are a number of methods to determine the quality of the sequencing data that you will assemble.  First, one can look at the quality scores of your sequencing reads and if desired, trim reads with quality scores that are not sufficient for your needs.  A vast number of tools are available to perform quality trimming of sequencing reads, including tools with nice tutorials including Sickel (https://github.com/najoshi/sickle and http://2014-5-metagenomics-workshop.readthedocs.org/en/latest/assembly/qtrim.html), FastX Toolkit (http://hannonlab.cshl.edu/fastx_toolkit/ and http://khmer-protocols.readthedocs.org/en/v0.8-1/metagenomics/1-quality.html), and FastQC (http://www.bioinformatics.babraham.ac.uk/projects/fastqc/ and http://ged.msu.edu/angus/tutorials-2013/short-read-quality-evaluation.html).\n",
      " \n",
      "The sequencing data file you have downloaded is a \"fastq\" text file, where data describing each sequencing read is shown on four lines.  Let's take a quick look:\n",
      "\n",
      "The first line (starting with an @) is a read identifier, the second is the DNA sequence, the third another identifier (same as line 1, but starting with a +(or sometimes only consisting of a +)) and the fourth is a Phred quality score symbol for each base in the read. The quality score is based on the ASCII character code used by computer keyboards (http://www.ascii-code.com/). Illumina's current sequencing pipeline (as of January 2012) uses an offset of 64, so that an @ (ASCII code 64) is 0, and h (ASCII code 104) is 40 (other versions of the pipeline might use different offsets, however. If you have data with a different offset value, you will need to modify your commands accordingly to inform programs that this is the case). The quality score for each base ranges from -5 to 40 and is defined as Qphred =-10 log10(p), where p is the estimated probability of a base call being wrong. So a Qphred of 20 corresponds to a 99 % probability of a correctly identified base. The Illumina sequencing machine produces reads of a predefined length (currently 50 or 101 bases). As the mRNA was fragmented into small pieces before the adapters were ligated, it is possible that partial adapter sequences have been sequenced if any sequenced fragment was shorter than the read length. Also, it is possible that adapter-only sequences have been sequenced.\n",
      "Before we can use our data to answer any biological questions, we must remove poorly identified bases as well as any adapter sequences from our reads. To evaluate the data set, it is also useful to know what the distribution of quality scores and nucleotides looks like. As the FASTQ files are too large to overview manually, we have to summarize the data and graph it, either by using command-line based software or web server applications. It is also useful to know the fraction of duplicate reads (identical reads present more than once in the dataset) and singletons (reads only present once in the dataset), for which we use command-line tools. There is still debate over whether duplicate reads represent very common transcripts or if they are due to primer or PCR bias, but a large fraction of duplicate reads may be indicative of a poor cDNA library. We have typically seen fractions of duplicate reads of 30-50 %."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 4 SRR172903.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "@SRR172903.1 USI-EAS376:2:1:2:1414 length=75\r\n",
        "CTTACCACCAGGAACNAACTTTGAGATTCCAAAAGATCGAGTACCAGAGGGATGGACAGTAACAGTAGATCCAGA\r\n",
        "+SRR172903.1 USI-EAS376:2:1:2:1414 length=75\r\n",
        "BB@BBBABB????<=%04@@>A?6><<AB@7:@A?@>A@AA8@>59==???887905<?6>25=###########\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* This first line (starting with \"@SRR172903.1\") is the read identifier, it usually shows the read ID, some information for the sequencing facility about the run that it was obtained on.\n",
      "* The second line is the DNA sequence.\n",
      "* The third line is the same as the first line but replacing the \"@\" with a \"+\", sometimes this is only a \"+\" in some datasets\n",
      "* The fourth line gives you information on the quality score of each base pair for the DNA sequence.  Note that it is the same length as the DNA sequence and that quality scores are based on ASCII character scores (with an offset determined by the sequencing technology, Illumina is currently an offset of 64, e.g., ASCII code 64 = 0 Phred score).  The quality score is equal to the -10 * log (p), where p is the probability of the base being called wrong (e.g., if Q= 20, p=0.01, 1% probability base is called wrong).    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Checking the diversity - What is the distribution of \"Who is There?\"\n",
      "\n",
      "An advantage of metagenomic sequencing is the ability to quantify microbial diversity in an environment without the need to first cultivate cells.  Typically, most studies access taxonomic diversity (especially with the usage of targeted sequencing of the 16S rRNA gene*).  Diversity can also be measured in the representation of specific sequence patterns in a metagenome.  For example, one can quantify the abundance of unique nucleotide \"words\" of length K, or k-mers, in a metagenome.  These k-mers can also be used in the assembly of metagenomes where overlapping k-mers are indicative of reads that should be connected together.  The diversity of these k-mers can give you insight into the the diversity of your sample.  Further, since assembly compares each k-mer against all k-mers, larger numbers of k-mers present will require more computational memory. A nice review on k-mers and assembly is Miller et al.\n",
      "\n",
      "(*Note that 16S rRNA amplicon sequencing is a targeted approach and not considered metagenomics in this review.  Shotgun metagenomic sequencing uses DNA extracted from all cells in a community and sequenced.  Targeted sequencing amplifies a specific genomic locus and independently sequenced.  A great review on metagenome analysis is Sharpton et al.)\n",
      "\n",
      "The first thing we will do is install khmer (www.github.com/ged-lab/khmer) -- it contains a suite of khmer and pre-assembly tools.  We will use it for k-mer counting here.  Once you run the script below, you can use khmer's many tools."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash khmer-install.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following script is contained within the *khmer* package and can estimate the total unique number of k-mers in your dataset.  Use cases for this might be a) determining how diverse a metagenome is compared to e.g., a bacterial genome for assembly, b) to compare k-mer diversity among multiple metagenomes, c) exploring the impacts of choice of length k for assembly.\n",
      "\n",
      "Next, to estimate the number unique k-mers in the datasets for multiple k's (17, 21, 25, 29, 33, 37), execute the scripts below.  The script output will identify the unique k-mers but will also save in a report named unique_count. (This takes about 15 minutes on a large instance and 8-10 minutes on an extra large.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python unique-kmers.py -R unique_count -k 17 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 21 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 25 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 29 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 33 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 37 SRR172903.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that this file now has in the first column the k-mer length and in the second column the estimated number of words of length k in the metagenomes. If you had multiple genomes, you could compare diversity of e.g., the total number of k-mers across datasets.  To view the results of the file, you can use the concatentate program/command \"cat\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat unique_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. Getting a sequence coverage profile:  What genes are present in my metagenome?\n",
      "\n",
      "\n",
      "Most metagenomic analysis require one to estimate the abundance of reference genes (e.g., orginating from genomes or one's own metagenomic assembly).  This tutorial will cover both cases where references are available or unavailable (requiring de novo assembly).  \n",
      "\n",
      "\n",
      "### 5. Case I - Reference genomes available.  \n",
      "\n",
      "For the mock HMP metagenome, the HMP has sequenced the genomes of the isolates used for this simulated dataset.  The list of these genomes can be obtained on the HMP website, and we provide it here in a Github repository, a tool used for collaboratively sharing data and code.  The command below will download data for this tutorial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ncbi_acc.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following command downloads all the genomes for each ID in the above list into a directory called \"genomes\".  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python fetch-genomes-fasta.py ncbi_acc.txt genomes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 6. Estimating abundance of assembled contigs\n",
      "\n",
      "To estimate the representation of reference genes or genomes in your metagenome, you can align reads to references using read mapping software (e.g., Bowtie2, BWA, etc.).  In this tutorial, we will use Bowtie2 which we will install on this server.  We will then be  mapping the metagenome to a single reference genome (that we downloaded above). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wget http://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip\n",
      "!unzip bowtie2-2.2.5-linux-x86_64.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I've written a script that will automatically map a set of reads to a given reference and output a file containing the number of reads that are mapped to a given reference.  To use this script, we'll also need to install samtools.  A samfile is a super compressed file that efficiently stores mapped information from mappers.  Samtools helps us interact with this file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!apt-get install samtools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To map reads to a reference, we have provided an easy to use program.  The steps the program performs are as follows:\n",
      "\n",
      "* Index your reference genome,\n",
      "* Map reads to your index genome (with default bowtie parameters),\n",
      "* Use Samtools to estimate the number of reads mapped, number of reads unmapped, and provide a tab delimited file with each line consisting of reference sequence name, sequence length, # mapped reads and # unmapped reads.\n",
      "\n",
      "This takes about 8-10 minutes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash bowtie.sh genomes/NC_000913.2.fa SRR172903.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can look at the total number of reads mapped and unmapped from our metagenome to the genome NC_000913.2.  We can also get a file that shows the reference sequence name (first column), reference sequence length (second column), # mapped reads (third column) and # unmapped reads (last column).  The other columns contain information that samtools can use for other queries, you can read about samtools here, http://samtools.sourceforge.net/samtools.shtml."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads-mapped.count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads-unmapped.count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads.by.contigs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want a challenge, you can try mapping the metagenome to all reference genomes provided in the genome folder.  To do so, try concatentating all genomes into one file (using this command:  \"cat genomes/*fa >> all-genomes.fa\") and running the program on all-genomes.fa instead of NC_000913.2.fa."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "### 7. Case II - *De novo* assembly of reference genes.\n",
      "\n",
      "\n",
      "###  Assembly of the HMP mock metagenome\n",
      "\n",
      "Assembly is the process of merging overlapping metagenomic reads from *hopefully* the same genome into a longer, continguous sequence (most commonly called a contig).  It is advantageous in that it provides longer lengths for sequences that can later be used as references (that may be previously unknown), reduces the dataset size for analysis, and provides references that are not dependent on previous knowledge.  \n",
      "\n",
      "The choice of what assembler to use is not an easy one and is a subject of debate (see http://assemblathon.org).  It is most important to remember that an assembly is a *hypothesized* consensus representation of your dataset.  The assembly itself is an initial step that needs to be followed by an evaluation of its accuracy and usefulness.  For most assemblers, the inputs are sequencing reads and paramters for the assembly software. For this tutorial, we will be completing the assembly with an assembler published in 2014 called Megahit (Li et al., 2015, https://github.com/voutcn/megahit).  Sharpton's review (Sharpton, 2014) also reviews quite nicely some of the many assembly programs and approaches for metagenomic assembly.  \n",
      "\n",
      "To reduce the memory that is needed, it is often advantageous to normalize the distribution of k-mers in a metagenome.  Removing extraneous information not needed for assembly also removes reads that may contain errors and may improve assembly (http://arxiv.org/abs/1203.4802).  These scripts and tutorials are available at http://ged.msu.edu/angus/diginorm-2012/tutorial.html.\n",
      "\n",
      "For this tutorial, we will assemble our metagenome with the Megathit assembler so first we have to install it.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash install-megahit.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This assembly will take about 15 minutes and will save the assembly to a folder names \"megahit_assembly\".  You can read about the parameters to this program, such as --memory that specifies the maximum memory that can be used on the megahit software repo, https://github.com/voutcn/megahit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!megahit/megahit --memory 10e9 -l 250 --k-max 81 -r SRR172903.fastq --cpu-only -o megahit_assembly"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To take a look at the assembly, let's run the khmer assembly summary program on it, the final contigs are in megahit_assembly/final.contigs.fa.  Let's get statistics on all contigs greater than or equal to 200 bp."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python khmer/sandbox/assemstats3.py 200 megahit_assembly/final.contigs.fa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 8. Estimating abundances of contigs\n",
      "\n",
      "Once the assembly is finished, you have a set of reference contigs which you can now estimate the abundance of the metagenome.  The approach for doing so is identical to that shown above where you use reference genomes.\n",
      "\n",
      "This will take about 20 minutes. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash bowtie.sh megahit_assembly/final.contigs.fa SRR172903.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can take a look at the results of the mapping much like you did above when we were mapping reads to the NCBI genome."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads-mapped.count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads-unmapped.count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads.by.contigs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 9. Annotating the assembled contigs\n",
      "\n",
      "Sequencing is often used to determine \"who\" and/or \"what\" is in your sample.  In our case, we know that the HMP mock community should orignate from a set of genomes (which we actually downlaoded above).  One of the most popular tools of comparing an unknown sequence to a known reference is The Basic Local Alignment Search Tool (or BLAST).  To identify the origin of our contigs, we will align assembled contigs to the genomes used in the HMP mock community.\n",
      "\n",
      "The first thing we will do is download the BLAST software.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.2.30+-x64-linux.tar.gz\n",
      "!tar -xvf ncbi-blast-2.2.30+-x64-linux.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we will make a searchable database for the BLAST software.  First, we'll concatenate all the genomes in the genomes directory to one file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat genomes/*fa >> all-genomes.fa\n",
      "!ncbi-blast-2.2.30+/bin/makeblastdb -in all-genomes.fa -dbtype nucl -out all-genomes\n",
      "!ncbi-blast-2.2.30+/bin/blastn -db all-genomes -query megahit_assembly/final.contigs.fa -outfmt 6 -out contigs.x.all-genomes.blastnout"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above command aligns each query (each sequence in the assembled final.contings.fa file) with each sequence (e.g., genome in all-genomes.fa).  The -outfmt tells the program to save the results in a tab-delimited format in the -out file contigs.x.all-genomes.blastnout.\n",
      "\n",
      "Let's take a look at the first 10 lines of that file.  You'll see the query (contig) and the hit (genome) followed by the percent identity, the length of alignment, mismatch counts, gap open counts, query start position, query end position, subject start position, subject end position, E-value, and bit score. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 10 contigs.x.all-genomes.blastnout"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now you have all the information you need to produce the following information:\n",
      "\n",
      "* Sequence Abundance Information:  Sequence (e.g., contig) and abundance (e.g., number of mapped reads)\n",
      "* Sequence Annotation Information:  Sequence (eg., contig) and NCBI genome\n",
      "\n",
      "You'll note that this is similar to 16S rRNA amplicon analysis where you'd have an OTU abundance table and OTU best hit annotations.  For metagenomic analysis, this information takes you into further analysis and visualization packages like PhyloSeq in R (http://joey711.github.io/phyloseq/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you run through this tutorial on this workbook, a good exercise would be to try to run the assembly outside the IPython Notebook environment.  To do so, you can log into your EC2 instance, navigate to the directory where this data is stored (cd /mnt/frontiers-review-2015), and you could run every command in this notebook on the command line (with the exception of the \"!\" at the beginning of each command in the notebook.  Also, note that you will not have to reinstall the software."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}