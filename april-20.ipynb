{
 "metadata": {
  "name": "april-20"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "The largest challenge facing the usage of metagenomic approaches in microbiology is the need to extend traditional microbiology training to include metagenomic or sequencing data analysis. Sean Eddy (a compuational biologist at the Howard Hughes Medical Institute) nicely describes the impacts of high throughput sequencing on biology and its training in his keynote address (http://cryptogenomicon.org/2014/11/01/high-throughput-sequencing-for-neuroscience/#more-858).\n",
      "\n",
      "To facilitate the barriers to microbiologists for metagenomic assembly, we have complemented this review with a tutorial of how to estimate the abundance of reference genes in a metagenome.  We include approaches that include using references that are both (i) available genome references or (ii) assembled from the metagenome. In general, to complete this tutorial and most metagenomic assembly, one would need:\n",
      "\n",
      "* Access to a server.  Most metagenomic assembly will require more memory than most researchers will have on their personal computers.  In this tutorial, we will provide training on the publicly accessible Amazon EC2 instances which can be rented by anyone with a registered account.\n",
      "* Access to a metagenomic dataset.  We have selected the usage of the HMP Mock Community WGS dataset (http://www.hmpdacc.org/HMMC/) for this tutorial given its availability, practical size, and availability of reference genomes.  This dataset represents a synthetic metagenome of 21 known organisms for which DNA was extracted from cultured isolates, combined, and sequenced.\n",
      "* Software for assembly, read mapping, and annotation.  We will demonstrate the installation of this software on an Ubuntu-based server.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### How to use this IPython Notebook\n",
      "IPython notebooks are very useful to collaboratively train bioinformatics. These notebooks have recently been featured in Nature News (http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261 and http://www.nature.com/news/programming-pick-up-python-1.16833)\n",
      "\n",
      "In using these notebooks, there are a few imporant things to note. There are two types of content in this tutorial: text and code. This content is placed in this notebook as \"cells\". If you click around on this page, you'll see different cells highlighted. To execute each cell (regardless of content), you hit on your keyboard SHIFT+ENTER. If the cell contains text, the content will be displayed directly. If the cell contains code, the code will then execute. Also, you can execute all cells in the notebook by going to the Cell tab where File, Edit, View, Insert, Cell... are in the top left of this webpage and selecting Run all."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.  Download the tutorial dataset.\n",
      "\n",
      "We will begin this tutorial by downloading the HMP mock metagenome from the NCBI Short Read Archives (SRA).  Many public metagenomes are stored as SRA files in the NCBI. The easiest way to get these SRA files is to use a special set of tools called the *sratoolkit*.  If you have your dataset SRA run ID (in this case SRR172903), you can download the dataset and convert it to the standard \"fasta\" or \"fastq\" sequencing format is to use a special program to convert the file.  \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wget http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.4.5-2/sratoolkit.2.4.5-2-ubuntu64.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--2015-04-20 15:15:21--  http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.4.5-2/sratoolkit.2.4.5-2-ubuntu64.tar.gz\r\n",
        "Resolving ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)... 130.14.250.11, 2607:f220:41e:250::11\r\n",
        "Connecting to ftp-trace.ncbi.nlm.nih.gov (ftp-trace.ncbi.nlm.nih.gov)|130.14.250.11|:80... connected.\r\n",
        "HTTP request sent, awaiting response... 200 OK\r\n",
        "Length: 62432226 (60M) [application/x-gzip]\r\n",
        "Saving to: \u2018sratoolkit.2.4.5-2-ubuntu64.tar.gz\u2019\r\n",
        "\r\n",
        "\r",
        " 0% [                                       ] 0           --.-K/s              "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "21% [=======>                               ] 13,354,408  61.6MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "67% [=========================>             ] 41,878,656  98.2MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100%[======================================>] 62,432,226   105MB/s   in 0.6s   \r\n",
        "\r\n",
        "2015-04-20 15:15:22 (105 MB/s) - \u2018sratoolkit.2.4.5-2-ubuntu64.tar.gz\u2019 saved [62432226/62432226]\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tar -xvf sratoolkit.2.4.5-2-ubuntu64.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/README\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/README-blastn\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/README-vdb-config\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/ncbi/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/ncbi/default.kfg\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/ncbi/vdb-copy.kfg\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/abi-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/align-info\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/align-info.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/align-info.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/bam-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/bam-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/bam-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/blastn_vdb\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/blastn_vdb.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/blastn_vdb.2.2.30-2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/cache-mgr\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cache-mgr.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cache-mgr.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cg-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cg-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/cg-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/fastq-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/helicos-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/helicos-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/helicos-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/illumina-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/kar\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kar.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kar.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/kdbmeta\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kdbmeta.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/kdbmeta.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/latf-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/latf-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/latf-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/pacbio-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/pacbio-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/pacbio-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/prefetch\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/prefetch.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/prefetch.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/rcexplain\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/rcexplain.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/rcexplain.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/remote-fuser\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/remote-fuser.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/remote-fuser.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sam-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sam-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sam-dump.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-dump.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sff-load.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-kar\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-kar.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-kar.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-pileup\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-pileup.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-pileup.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-sort\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-sort.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-sort.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-stat\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-stat.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/sra-stat.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srapath\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srapath.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srapath.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/srf-load\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srf-load.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/srf-load.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/tblastn_vdb\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/tblastn_vdb.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/tblastn_vdb.2.2.30-2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/test-sra\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/test-sra.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/test-sra.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-config\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-config.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-config.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-copy\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-copy.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-copy.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-decrypt\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-decrypt.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-decrypt.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-dump\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-dump.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-dump.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-encrypt\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-encrypt.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-encrypt.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-lock\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-lock.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-lock.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-passwd\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-passwd.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-passwd.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-unlock\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-unlock.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-unlock.2.4.5\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-validate\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-validate.2\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/bin/vdb-validate.2.4.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "sratoolkit.2.4.5-2-ubuntu64/example/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/base-stats.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/dump-reference.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/gene-lookup.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/mismatch-stats.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/quality-stats.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/simplefastq.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/example/perl/splitfastq.pl\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/align.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/mate-cache.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/qstat.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/refseq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/align/seq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/insdc.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/seq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/insdc/sra.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/clip.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/ncbi.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/pnbrdb.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/seq-graph.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/seq.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/spotname.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/sra.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/stats.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/varloc.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/ncbi/wgs-contig.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/454.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/abi.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/helicos.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/illumina.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/ion-torrent.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/pacbio.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/sra/pevents.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/vdb/\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/vdb/built-in.vschema\r\n",
        "sratoolkit.2.4.5-2-ubuntu64/schema/vdb/vdb.vschema\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that we now have a file containing the software with the \"ls\" command.  You'll also see this notebook in the list of files in the present location we are working in."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "april-20.ipynb\t\t     kmer-count-plot.py\r\n",
        "april_8_notebook.ipynb\t     LICENSE.md\r\n",
        "bowtie.sh\t\t     ncbi_acc.txt\r\n",
        "download.sh\t\t     parse-genbank-mult-records.py\r\n",
        "fetch-genomes-fasta.py\t     parse-genbank.py\r\n",
        "ipython_notebook_config.py   README.md\r\n",
        "ipython_notebook_config.py~  sratoolkit.2.4.5-2-ubuntu64\r\n",
        "khmer\t\t\t     sratoolkit.2.4.5-2-ubuntu64.tar.gz\r\n",
        "khmer-install.sh\t     test.ipynb\r\n",
        "khmer.sh\t\t     unique-kmers.py\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll use the installed sratoolkit program to download the HMP mock dataset in \"fastq\" format. (This takes a minute or two.  You'll find that patience is require for working with metagenomes.  The nice thing about working in the cloud is that you are \"renting\" the computational power so it is not using your personal computer's memory -- freeing it up for things you can do while waiting.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!sratoolkit.2.4.5-2-ubuntu64/bin/fastq-dump SRR172903"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Read 7932819 spots for SRR172903\r\n",
        "Written 7932819 spots for SRR172903\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Checking the diversity - What is the distribution of \"Who is There?\"\n",
      "\n",
      "An advantage of metagenomic sequencing is the ability to quantify microbial diversity in an environment without the need to first cultivate cells.  Typically, most studies access taxonomic diversity (especially with the usage of targeted sequencing of the 16S rRNA gene*).  Diversity can also be measured in the representation of specific sequence patterns in a metagenome.  For example, one can quantify the abundance of unique nucleotide \"words\" of length K, or k-mers, in a metagenome.  These k-mers are also used in the assembly of metagenomes where overlapping k-mers are indicative of reads that should be connected together.  The diversity of these k-mers can give you insight into the the diversity of your sample.  Further, since assembly compares each k-mersagainst all k-mers, increasing k-mers present will require more computational memory. A nice review on k-mers and assembly is Miller et al.\n",
      "\n",
      "(*Note that 16S rRNA amplicon sequencing is a targeted approach and not considered metagenomics.  Metagenomic sequencing uses DNA extracted from all cells in a community and sequenced.  Targeted sequencing amplifies a specific genomic locus and independently sequenced.  A great review on metagenome analysis is Sharpton et al.)\n",
      "\n",
      "The first thing we will do is install khmer (www.github.com/ged-lab/khmer) -- it contains a suite of khmer and pre-assembly tools.  We will use it for k-mer counting here.  Once you run the script below, you can use khmer's many tools."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash khmer-install.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cloning into 'khmer'...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "remote: Counting objects: 30728, done.\u001b[K\r\n",
        "remote: Compressing objects:   0% (1/115)   \u001b[K\r",
        "remote: Compressing objects:   1% (2/115)   \u001b[K\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "remote: Compressing objects:   2% (3/115)   \u001b[K\r",
        "remote: Compressing objects:   3% (4/115)   \u001b[K\r",
        "remote: Compressing objects:   4% (5/115)   \u001b[K\r",
        "remote: Compressing objects:   5% (6/115)   \u001b[K\r",
        "remote: Compressing objects:   6% (7/115)   \u001b[K\r",
        "remote: Compressing objects:   7% (9/115)   \u001b[K\r",
        "remote: Compressing objects:   8% (10/115)   \u001b[K\r",
        "remote: Compressing objects:   9% (11/115)   \u001b[K\r",
        "remote: Compressing objects:  10% (12/115)   \u001b[K\r",
        "remote: Compressing objects:  11% (13/115)   \u001b[K\r",
        "remote: Compressing objects:  12% (14/115)   \u001b[K\r",
        "remote: Compressing objects:  13% (15/115)   \u001b[K\r",
        "remote: Compressing objects:  14% (17/115)   \u001b[K\r",
        "remote: Compressing objects:  15% (18/115)   \u001b[K\r",
        "remote: Compressing objects:  16% (19/115)   \u001b[K\r",
        "remote: Compressing objects:  17% (20/115)   \u001b[K\r",
        "remote: Compressing objects:  18% (21/115)   \u001b[K\r",
        "remote: Compressing objects:  19% (22/115)   \u001b[K\r",
        "remote: Compressing objects:  20% (23/115)   \u001b[K\r",
        "remote: Compressing objects:  21% (25/115)   \u001b[K\r",
        "remote: Compressing objects:  22% (26/115)   \u001b[K\r",
        "remote: Compressing objects:  23% (27/115)   \u001b[K\r",
        "remote: Compressing objects:  24% (28/115)   \u001b[K\r",
        "remote: Compressing objects:  25% (29/115)   \u001b[K\r",
        "remote: Compressing objects:  26% (30/115)   \u001b[K\r",
        "remote: Compressing objects:  27% (32/115)   \u001b[K\r",
        "remote: Compressing objects:  28% (33/115)   \u001b[K\r",
        "remote: Compressing objects:  29% (34/115)   \u001b[K\r",
        "remote: Compressing objects:  30% (35/115)   \u001b[K\r",
        "remote: Compressing objects:  31% (36/115)   \u001b[K\r",
        "remote: Compressing objects:  32% (37/115)   \u001b[K\r",
        "remote: Compressing objects:  33% (38/115)   \u001b[K\r",
        "remote: Compressing objects:  34% (40/115)   \u001b[K\r",
        "remote: Compressing objects:  35% (41/115)   \u001b[K\r",
        "remote: Compressing objects:  36% (42/115)   \u001b[K\r",
        "remote: Compressing objects:  37% (43/115)   \u001b[K\r",
        "remote: Compressing objects:  38% (44/115)   \u001b[K\r",
        "remote: Compressing objects:  39% (45/115)   \u001b[K\r",
        "remote: Compressing objects:  40% (46/115)   \u001b[K\r",
        "remote: Compressing objects:  41% (48/115)   \u001b[K\r",
        "remote: Compressing objects:  42% (49/115)   \u001b[K\r",
        "remote: Compressing objects:  43% (50/115)   \u001b[K\r",
        "remote: Compressing objects:  44% (51/115)   \u001b[K\r",
        "remote: Compressing objects:  45% (52/115)   \u001b[K\r",
        "remote: Compressing objects:  46% (53/115)   \u001b[K\r",
        "remote: Compressing objects:  47% (55/115)   \u001b[K\r",
        "remote: Compressing objects:  48% (56/115)   \u001b[K\r",
        "remote: Compressing objects:  49% (57/115)   \u001b[K\r",
        "remote: Compressing objects:  50% (58/115)   \u001b[K\r",
        "remote: Compressing objects:  51% (59/115)   \u001b[K\r",
        "remote: Compressing objects:  52% (60/115)   \u001b[K\r",
        "remote: Compressing objects:  53% (61/115)   \u001b[K\r",
        "remote: Compressing objects:  54% (63/115)   \u001b[K\r",
        "remote: Compressing objects:  55% (64/115)   \u001b[K\r",
        "remote: Compressing objects:  56% (65/115)   \u001b[K\r",
        "remote: Compressing objects:  57% (66/115)   \u001b[K\r",
        "remote: Compressing objects:  58% (67/115)   \u001b[K\r",
        "remote: Compressing objects:  59% (68/115)   \u001b[K\r",
        "remote: Compressing objects:  60% (69/115)   \u001b[K\r",
        "remote: Compressing objects:  61% (71/115)   \u001b[K\r",
        "remote: Compressing objects:  62% (72/115)   \u001b[K\r",
        "remote: Compressing objects:  63% (73/115)   \u001b[K\r",
        "remote: Compressing objects:  64% (74/115)   \u001b[K\r",
        "remote: Compressing objects:  65% (75/115)   \u001b[K\r",
        "remote: Compressing objects:  66% (76/115)   \u001b[K\r",
        "remote: Compressing objects:  67% (78/115)   \u001b[K\r",
        "remote: Compressing objects:  68% (79/115)   \u001b[K\r",
        "remote: Compressing objects:  69% (80/115)   \u001b[K\r",
        "remote: Compressing objects:  70% (81/115)   \u001b[K\r",
        "remote: Compressing objects:  71% (82/115)   \u001b[K\r",
        "remote: Compressing objects:  72% (83/115)   \u001b[K\r",
        "remote: Compressing objects:  73% (84/115)   \u001b[K\r",
        "remote: Compressing objects:  74% (86/115)   \u001b[K\r",
        "remote: Compressing objects:  75% (87/115)   \u001b[K\r",
        "remote: Compressing objects:  76% (88/115)   \u001b[K\r",
        "remote: Compressing objects:  77% (89/115)   \u001b[K\r",
        "remote: Compressing objects:  78% (90/115)   \u001b[K\r",
        "remote: Compressing objects:  79% (91/115)   \u001b[K\r",
        "remote: Compressing objects:  80% (92/115)   \u001b[K\r",
        "remote: Compressing objects:  81% (94/115)   \u001b[K\r",
        "remote: Compressing objects:  82% (95/115)   \u001b[K\r",
        "remote: Compressing objects:  83% (96/115)   \u001b[K\r",
        "remote: Compressing objects:  84% (97/115)   \u001b[K\r",
        "remote: Compressing objects:  85% (98/115)   \u001b[K\r",
        "remote: Compressing objects:  86% (99/115)   \u001b[K\r",
        "remote: Compressing objects:  87% (101/115)   \u001b[K\r",
        "remote: Compressing objects:  88% (102/115)   \u001b[K\r",
        "remote: Compressing objects:  89% (103/115)   \u001b[K\r",
        "remote: Compressing objects:  90% (104/115)   \u001b[K\r",
        "remote: Compressing objects:  91% (105/115)   \u001b[K\r",
        "remote: Compressing objects:  92% (106/115)   \u001b[K\r",
        "remote: Compressing objects:  93% (107/115)   \u001b[K\r",
        "remote: Compressing objects:  94% (109/115)   \u001b[K\r",
        "remote: Compressing objects:  95% (110/115)   \u001b[K\r",
        "remote: Compressing objects:  96% (111/115)   \u001b[K\r",
        "remote: Compressing objects:  97% (112/115)   \u001b[K\r",
        "remote: Compressing objects:  98% (113/115)   \u001b[K\r",
        "remote: Compressing objects:  99% (114/115)   \u001b[K\r",
        "remote: Compressing objects: 100% (115/115)   \u001b[K\r",
        "remote: Compressing objects: 100% (115/115), done.\u001b[K\r\n",
        "Receiving objects:   0% (1/30728)   \r",
        "Receiving objects:   1% (308/30728)   \r",
        "Receiving objects:   2% (615/30728)   \r",
        "Receiving objects:   3% (922/30728)   \r",
        "Receiving objects:   4% (1230/30728)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:   5% (1537/30728)   \r",
        "Receiving objects:   6% (1844/30728)   \r",
        "Receiving objects:   7% (2151/30728)   \r",
        "Receiving objects:   8% (2459/30728)   \r",
        "Receiving objects:   9% (2766/30728)   \r",
        "Receiving objects:  10% (3073/30728)   \r",
        "Receiving objects:  11% (3381/30728)   \r",
        "Receiving objects:  12% (3688/30728)   \r",
        "Receiving objects:  13% (3995/30728)   \r",
        "Receiving objects:  14% (4302/30728)   \r",
        "Receiving objects:  15% (4610/30728)   \r",
        "Receiving objects:  16% (4917/30728)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  17% (5224/30728)   \r",
        "Receiving objects:  18% (5532/30728)   \r",
        "Receiving objects:  19% (5839/30728)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  20% (6146/30728), 8.94 MiB | 17.83 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  21% (6453/30728), 8.94 MiB | 17.83 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  21% (6530/30728), 8.94 MiB | 17.83 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  22% (6761/30728), 17.09 MiB | 17.06 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  23% (7068/30728), 17.09 MiB | 17.06 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  24% (7375/30728), 17.09 MiB | 17.06 MiB/s   \r",
        "Receiving objects:  25% (7682/30728), 17.09 MiB | 17.06 MiB/s   \r",
        "Receiving objects:  26% (7990/30728), 17.09 MiB | 17.06 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  27% (8297/30728), 17.09 MiB | 17.06 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  28% (8604/30728), 17.09 MiB | 17.06 MiB/s   \r",
        "Receiving objects:  29% (8912/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  30% (9219/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  31% (9526/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  32% (9833/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  33% (10141/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  34% (10448/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  35% (10755/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  36% (11063/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  37% (11370/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  38% (11677/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  39% (11984/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  40% (12292/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  41% (12599/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  42% (12906/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  43% (13214/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  44% (13521/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  45% (13828/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  46% (14135/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  47% (14443/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  48% (14750/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  49% (15057/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  50% (15364/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  51% (15672/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  52% (15979/30728), 31.42 MiB | 20.90 MiB/s   \r",
        "Receiving objects:  53% (16286/30728), 31.42 MiB | 20.90 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  53% (16396/30728), 42.83 MiB | 21.37 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  53% (16397/30728), 53.19 MiB | 21.23 MiB/s   \r",
        "Receiving objects:  54% (16594/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  55% (16901/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  56% (17208/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  57% (17515/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  58% (17823/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  59% (18130/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  60% (18437/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  61% (18745/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  62% (19052/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  63% (19359/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  64% (19666/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  65% (19974/30728), 64.29 MiB | 21.34 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  66% (20281/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  67% (20588/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  68% (20896/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  69% (21203/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  70% (21510/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  71% (21817/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  72% (22125/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  73% (22432/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  74% (22739/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  75% (23046/30728), 64.29 MiB | 21.34 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  76% (23354/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  77% (23661/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  78% (23968/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  79% (24276/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  80% (24583/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  81% (24890/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  82% (25197/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  83% (25505/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  84% (25812/30728), 64.29 MiB | 21.34 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  85% (26119/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  86% (26427/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  87% (26734/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  88% (27041/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  89% (27348/30728), 64.29 MiB | 21.34 MiB/s   \r",
        "Receiving objects:  90% (27656/30728), 64.29 MiB | 21.34 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  91% (27963/30728), 76.59 MiB | 21.79 MiB/s   \r",
        "Receiving objects:  92% (28270/30728), 76.59 MiB | 21.79 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28578/30728), 76.59 MiB | 21.79 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28836/30728), 81.32 MiB | 20.25 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28836/30728), 82.03 MiB | 15.50 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28836/30728), 83.32 MiB | 11.00 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28836/30728), 84.61 MiB | 6.66 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28836/30728), 85.89 MiB | 1.98 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  93% (28836/30728), 87.18 MiB | 1.11 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  94% (28885/30728), 87.18 MiB | 1.11 MiB/s   \r",
        "Receiving objects:  95% (29192/30728), 87.18 MiB | 1.11 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  95% (29334/30728), 104.89 MiB | 4.92 MiB/s   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Receiving objects:  96% (29499/30728), 104.89 MiB | 4.92 MiB/s   \r",
        "Receiving objects:  97% (29807/30728), 104.89 MiB | 4.92 MiB/s   \r",
        "Receiving objects:  98% (30114/30728), 104.89 MiB | 4.92 MiB/s   \r",
        "Receiving objects:  99% (30421/30728), 104.89 MiB | 4.92 MiB/s   \r",
        "remote: Total 30728 (delta 59), reused 0 (delta 0), pack-reused 30611\u001b[K\r\n",
        "Receiving objects: 100% (30728/30728), 104.89 MiB | 4.92 MiB/s   \r",
        "Receiving objects: 100% (30728/30728), 111.10 MiB | 5.38 MiB/s, done.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:   0% (0/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:   1% (247/20736)   \r",
        "Resolving deltas:   2% (415/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:   3% (675/20736)   \r",
        "Resolving deltas:   4% (879/20736)   \r",
        "Resolving deltas:   5% (1066/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:   6% (1263/20736)   \r",
        "Resolving deltas:   7% (1482/20736)   \r",
        "Resolving deltas:   8% (1674/20736)   \r",
        "Resolving deltas:   9% (1885/20736)   \r",
        "Resolving deltas:  10% (2117/20736)   \r",
        "Resolving deltas:  11% (2312/20736)   \r",
        "Resolving deltas:  12% (2519/20736)   \r",
        "Resolving deltas:  13% (2707/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  14% (2927/20736)   \r",
        "Resolving deltas:  15% (3141/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  16% (3320/20736)   \r",
        "Resolving deltas:  17% (3526/20736)   \r",
        "Resolving deltas:  18% (3733/20736)   \r",
        "Resolving deltas:  19% (3953/20736)   \r",
        "Resolving deltas:  20% (4340/20736)   \r",
        "Resolving deltas:  22% (4616/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  23% (4799/20736)   \r",
        "Resolving deltas:  24% (5043/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  26% (5478/20736)   \r",
        "Resolving deltas:  27% (5600/20736)   \r",
        "Resolving deltas:  28% (5807/20736)   \r",
        "Resolving deltas:  29% (6014/20736)   \r",
        "Resolving deltas:  30% (6372/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  31% (6432/20736)   \r",
        "Resolving deltas:  32% (6639/20736)   \r",
        "Resolving deltas:  33% (6844/20736)   \r",
        "Resolving deltas:  34% (7106/20736)   \r",
        "Resolving deltas:  35% (7259/20736)   \r",
        "Resolving deltas:  36% (7472/20736)   \r",
        "Resolving deltas:  37% (7675/20736)   \r",
        "Resolving deltas:  38% (7880/20736)   \r",
        "Resolving deltas:  39% (8134/20736)   \r",
        "Resolving deltas:  40% (8304/20736)   \r",
        "Resolving deltas:  41% (8571/20736)   \r",
        "Resolving deltas:  42% (8762/20736)   \r",
        "Resolving deltas:  43% (8956/20736)   \r",
        "Resolving deltas:  44% (9133/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  45% (9424/20736)   \r",
        "Resolving deltas:  46% (9552/20736)   \r",
        "Resolving deltas:  47% (9755/20736)   \r",
        "Resolving deltas:  48% (9957/20736)   \r",
        "Resolving deltas:  49% (10164/20736)   \r",
        "Resolving deltas:  50% (10371/20736)   \r",
        "Resolving deltas:  51% (10581/20736)   \r",
        "Resolving deltas:  52% (10786/20736)   \r",
        "Resolving deltas:  53% (11026/20736)   \r",
        "Resolving deltas:  54% (11246/20736)   \r",
        "Resolving deltas:  55% (11405/20736)   \r",
        "Resolving deltas:  56% (11649/20736)   \r",
        "Resolving deltas:  57% (11822/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  58% (12050/20736)   \r",
        "Resolving deltas:  59% (12245/20736)   \r",
        "Resolving deltas:  60% (12499/20736)   \r",
        "Resolving deltas:  61% (12760/20736)   \r",
        "Resolving deltas:  62% (12859/20736)   \r",
        "Resolving deltas:  63% (13069/20736)   \r",
        "Resolving deltas:  64% (13279/20736)   \r",
        "Resolving deltas:  65% (13499/20736)   \r",
        "Resolving deltas:  66% (13699/20736)   \r",
        "Resolving deltas:  67% (14031/20736)   \r",
        "Resolving deltas:  68% (14141/20736)   \r",
        "Resolving deltas:  69% (14308/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  70% (14524/20736)   \r",
        "Resolving deltas:  71% (14770/20736)   \r",
        "Resolving deltas:  72% (15007/20736)   \r",
        "Resolving deltas:  73% (15202/20736)   \r",
        "Resolving deltas:  74% (15366/20736)   \r",
        "Resolving deltas:  75% (15554/20736)   \r",
        "Resolving deltas:  76% (15761/20736)   \r",
        "Resolving deltas:  77% (15979/20736)   \r",
        "Resolving deltas:  78% (16197/20736)   \r",
        "Resolving deltas:  79% (16427/20736)   \r",
        "Resolving deltas:  80% (16591/20736)   \r",
        "Resolving deltas:  81% (16813/20736)   \r",
        "Resolving deltas:  82% (17047/20736)   \r",
        "Resolving deltas:  83% (17220/20736)   \r",
        "Resolving deltas:  84% (17482/20736)   \r",
        "Resolving deltas:  85% (17659/20736)   \r",
        "Resolving deltas:  86% (17880/20736)   \r",
        "Resolving deltas:  87% (18102/20736)   \r",
        "Resolving deltas:  88% (18256/20736)   \r",
        "Resolving deltas:  89% (18481/20736)   \r",
        "Resolving deltas:  90% (18691/20736)   \r",
        "Resolving deltas:  91% (18937/20736)   \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving deltas:  92% (19084/20736)   \r",
        "Resolving deltas:  93% (19410/20736)   \r",
        "Resolving deltas:  94% (19496/20736)   \r",
        "Resolving deltas:  95% (19834/20736)   \r",
        "Resolving deltas:  96% (19939/20736)   \r",
        "Resolving deltas:  97% (20247/20736)   \r",
        "Resolving deltas:  98% (20352/20736)   \r",
        "Resolving deltas:  99% (20577/20736)   \r",
        "Resolving deltas: 100% (20736/20736)   \r",
        "Resolving deltas: 100% (20736/20736), done.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking connectivity... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running install\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking .pth file support in /usr/local/lib/python2.7/dist-packages/\r\n",
        "/usr/bin/python -E -c pass\r\n",
        "TEST PASSED: /usr/local/lib/python2.7/dist-packages/ appears to support .pth files\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "running bdist_egg\r\n",
        "running egg_info\r\n",
        "creating khmer.egg-info\r\n",
        "writing requirements to khmer.egg-info/requires.txt\r\n",
        "writing khmer.egg-info/PKG-INFO\r\n",
        "writing top-level names to khmer.egg-info/top_level.txt\r\n",
        "writing dependency_links to khmer.egg-info/dependency_links.txt\r\n",
        "writing manifest file 'khmer.egg-info/SOURCES.txt'\r\n",
        "reading manifest file 'khmer.egg-info/SOURCES.txt'\r\n",
        "reading manifest template 'MANIFEST.in'\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "warning: no previously-included files found matching 'third-party/zlib/Makefile'\r\n",
        "warning: no previously-included files found matching 'third-party/zlib/zconf.h'\r\n",
        "warning: no previously-included files matching '*.orig' found anywhere in distribution\r\n",
        "warning: no previously-included files matching '*.pyc' found anywhere in distribution\r\n",
        "writing manifest file 'khmer.egg-info/SOURCES.txt'\r\n",
        "installing library code to build/bdist.linux-x86_64/egg\r\n",
        "running install_lib\r\n",
        "running build_py\r\n",
        "creating build\r\n",
        "creating build/lib.linux-x86_64-2.7\r\n",
        "creating build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying khmer/utils.py -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying khmer/_version.py -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying khmer/__init__.py -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying khmer/thread_utils.py -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying khmer/kfile.py -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying khmer/khmer_args.py -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "creating build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_script_arguments.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_subset_graph.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_hashbits.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_lump.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_counting_hash.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_labelhash.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_graph.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_read_aligner.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_version.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_filter.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_hashbits_obj.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_threaded_sequence_processor.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_read_parsers.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_hll.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/khmer_tst_utils.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/__init__.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_sandbox_scripts.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_counting_single.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_functions.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying tests/test_scripts.py -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "copying khmer/_khmermodule.cc -> build/lib.linux-x86_64-2.7/khmer\r\n",
        "copying tests/.gitignore -> build/lib.linux-x86_64-2.7/khmer/tests\r\n",
        "creating build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/100-reads.fq.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/100-reads.fq.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/100-reads.fq.truncated.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/100-reads.fq.truncated.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/all-A.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/badversion-k12.ct -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/badversion-k12.ht -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/badversion-k32.stoptags -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/badversion-k32.tagset -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/biglump-random-20-a.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/casava_18-pe.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/combine_parts_1.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/empty-file -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/fakelump.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/fakelump.fa.stoptags.txt -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/filter-test-A.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/filter-test-B.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/goodversion-k12.ht -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/goodversion-k12.ht.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copying tests/test-data/goodversion-k32.stoptags -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/goodversion-k32.tagset -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/normC20k20.ct -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/old-style-format-w-comments.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/overlap.out -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-broken.fq.1 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-broken.fq.2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-broken2.fq.1 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-broken2.fq.2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-broken3.fq.1 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-broken3.fq.2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed-2.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed-broken.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed.fa.pe -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed.fa.se -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed.fq.pe -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired-mixed.fq.se -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired.fa.1 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired.fa.2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired.fq.1 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/paired.fq.2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-X2.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.even.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fa.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fa.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fa.part -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fq.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.fq.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-a.odd.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-20-b.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/random-31-c.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/real-partition-small.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/real-partition-tiny.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/single-read.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-2.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-2.fa.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-2.fa.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-2.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-2.paired.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-2.paired2.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-3.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-impaired.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-paired.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read-paired.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-abund-read.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-empty.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-empty.fa.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-error-reads.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-fastq-n-reads.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-fastq-reads.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-graph.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-graph2.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-graph5.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-labels.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-large.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-output-partitions.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-overlap1.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-overlap2.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-reads.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-reads.fq.bz2 -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-reads.fq.gz -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-short.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-sweep-contigs.fp -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-sweep-reads.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-sweep-reads.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/test-transcript.fa -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "copying tests/test-data/truncated.fq -> build/lib.linux-x86_64-2.7/khmer/tests/test-data\r\n",
        "running build_ext\r\n",
        "bash -c cd third-party/zlib && ( test Makefile -nt configure || bash ./configure --static ) && make -f Makefile.pic PIC\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking for gcc...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building static library libz.a version 1.2.8 with gcc.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking for off64_t... Yes.\r\n",
        "Checking for fseeko... Yes.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking for strerror... Yes.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking for unistd.h... Yes.\r\n",
        "Checking for stdarg.h... Yes.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking whether to use vs[n]printf() or s[n]printf()... using vs[n]printf().\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking for vsnprintf() in stdio.h... Yes.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Checking for return value of vsnprintf()... Yes.\r\n",
        "Checking for attribute(visibility) support... Yes.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/adler32.o adler32.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/crc32.o crc32.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/deflate.o deflate.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/infback.o infback.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/inffast.o inffast.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/inflate.o inflate.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/inftrees.o inftrees.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/trees.o trees.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/zutil.o zutil.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/compress.o compress.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/uncompr.o uncompr.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/gzclose.o gzclose.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/gzlib.o gzlib.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/gzread.o gzread.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -O3  -fPIC -D_LARGEFILE64_SOURCE=1 -DHAVE_HIDDEN -DPIC -c -o objs/gzwrite.o gzwrite.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bash -c cd third-party/bzip2 && make -f Makefile-libbz2_so all\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c blocksort.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "In function \u2018mainSort\u2019:\r\n",
        "blocksort.c:347:6: warning: inlining failed in call to \u2018mainGtU.part.0\u2019: call is unlikely and code size would grow [-Winline]\r\n",
        " Bool mainGtU ( UInt32  i1, \r\n",
        "      ^\r\n",
        "cc1: warning: called from here [-Winline]\r\n",
        "blocksort.c:347:6: warning: inlining failed in call to \u2018mainGtU.part.0\u2019: call is unlikely and code size would grow [-Winline]\r\n",
        " Bool mainGtU ( UInt32  i1, \r\n",
        "      ^\r\n",
        "cc1: warning: called from here [-Winline]\r\n",
        "blocksort.c:347:6: warning: inlining failed in call to \u2018mainGtU.part.0\u2019: call is unlikely and code size would grow [-Winline]\r\n",
        " Bool mainGtU ( UInt32  i1, \r\n",
        "      ^\r\n",
        "cc1: warning: called from here [-Winline]\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c huffman.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c crctable.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c randtable.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c compress.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c decompress.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -c bzlib.c\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#gcc -shared -Wl,-soname -Wl,libbz2.so.1.0 -o libbz2.so.1.0.6 blocksort.o huffman.o crctable.o randtable.o compress.o decompress.o bzlib.o\r\n",
        "#gcc -fpic -fPIC -Wall -Winline -O2 -g -D_FILE_OFFSET_BITS=64 -o bzip2-shared bzip2.c libbz2.so.1.0.6\r\n",
        "#rm -f libbz2.so.1.0\r\n",
        "#ln -s libbz2.so.1.0.6 libbz2.so.1.0\r\n",
        "building 'khmer._khmermodule' extension\r\n",
        "creating build/temp.linux-x86_64-2.7\r\n",
        "creating build/temp.linux-x86_64-2.7/khmer\r\n",
        "creating build/temp.linux-x86_64-2.7/lib\r\n",
        "creating build/temp.linux-x86_64-2.7/third-party\r\n",
        "creating build/temp.linux-x86_64-2.7/third-party/smhasher\r\n",
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c khmer/_khmermodule.cc -o build/temp.linux-x86_64-2.7/khmer/_khmermodule.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/trace_logger.cc -o build/temp.linux-x86_64-2.7/lib/trace_logger.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/perf_metrics.cc -o build/temp.linux-x86_64-2.7/lib/perf_metrics.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/read_parsers.cc -o build/temp.linux-x86_64-2.7/lib/read_parsers.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/kmer_hash.cc -o build/temp.linux-x86_64-2.7/lib/kmer_hash.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/hashtable.cc -o build/temp.linux-x86_64-2.7/lib/hashtable.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/hashbits.cc -o build/temp.linux-x86_64-2.7/lib/hashbits.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/labelhash.cc -o build/temp.linux-x86_64-2.7/lib/labelhash.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/counting.cc -o build/temp.linux-x86_64-2.7/lib/counting.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/subset.cc -o build/temp.linux-x86_64-2.7/lib/subset.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/read_aligner.cc -o build/temp.linux-x86_64-2.7/lib/read_aligner.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c lib/hllcounter.cc -o build/temp.linux-x86_64-2.7/lib/hllcounter.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x86_64-linux-gnu-gcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -fPIC -DVERSION=1.4-rc1-287-gcc8b337 -DSEQAN_HAS_BZIP2=1 -DSEQAN_HAS_ZLIB=1 -UNO_UNIQUE_RC -Ilib -Ithird-party/zlib -Ithird-party/bzip2 -Ithird-party/seqan/core/include -Ithird-party/smhasher -I/usr/include/python2.7 -c third-party/smhasher/MurmurHash3.cc -o build/temp.linux-x86_64-2.7/third-party/smhasher/MurmurHash3.o -O3 -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "c++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -D_FORTIFY_SOURCE=2 -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/khmer/_khmermodule.o build/temp.linux-x86_64-2.7/lib/trace_logger.o build/temp.linux-x86_64-2.7/lib/perf_metrics.o build/temp.linux-x86_64-2.7/lib/read_parsers.o build/temp.linux-x86_64-2.7/lib/kmer_hash.o build/temp.linux-x86_64-2.7/lib/hashtable.o build/temp.linux-x86_64-2.7/lib/hashbits.o build/temp.linux-x86_64-2.7/lib/labelhash.o build/temp.linux-x86_64-2.7/lib/counting.o build/temp.linux-x86_64-2.7/lib/subset.o build/temp.linux-x86_64-2.7/lib/read_aligner.o build/temp.linux-x86_64-2.7/lib/hllcounter.o build/temp.linux-x86_64-2.7/third-party/smhasher/MurmurHash3.o third-party/zlib/adler32.lo third-party/zlib/compress.lo third-party/zlib/crc32.lo third-party/zlib/deflate.lo third-party/zlib/gzclose.lo third-party/zlib/gzlib.lo third-party/zlib/gzread.lo third-party/zlib/gzwrite.lo third-party/zlib/infback.lo third-party/zlib/inffast.lo third-party/zlib/inflate.lo third-party/zlib/inftrees.lo third-party/zlib/trees.lo third-party/zlib/uncompr.lo third-party/zlib/zutil.lo third-party/bzip2/blocksort.o third-party/bzip2/huffman.o third-party/bzip2/crctable.o third-party/bzip2/randtable.o third-party/bzip2/compress.o third-party/bzip2/decompress.o third-party/bzip2/bzlib.o -o build/lib.linux-x86_64-2.7/khmer/_khmermodule.so -fopenmp\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating build/bdist.linux-x86_64\r\n",
        "creating build/bdist.linux-x86_64/egg\r\n",
        "creating build/bdist.linux-x86_64/egg/khmer\r\n",
        "creating build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_script_arguments.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_subset_graph.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_hashbits.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_lump.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_counting_hash.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_labelhash.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_graph.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_read_aligner.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_version.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_filter.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_hashbits_obj.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/.gitignore -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_threaded_sequence_processor.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_read_parsers.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_hll.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/khmer_tst_utils.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/__init__.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_sandbox_scripts.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "creating build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/filter-test-A.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/all-A.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/real-partition-small.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/goodversion-k12.ht -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-labels.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-output-partitions.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-b.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-sweep-contigs.fp -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/badversion-k12.ht -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed-2.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/100-reads.fq.truncated.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-fastq-reads.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-X2.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fa.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/empty-file -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/badversion-k12.ct -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-2.paired2.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-2.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-graph5.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fa.part -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-impaired.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed-broken.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fq.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-3.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-31-c.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-broken3.fq.2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-short.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-2.fa.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-2.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-reads.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fa.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-paired.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/goodversion-k32.stoptags -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-graph.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired.fq.1 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-broken2.fq.2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-empty.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/filter-test-B.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/truncated.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/100-reads.fq.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/fakelump.fa.stoptags.txt -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-overlap2.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-fastq-n-reads.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.odd.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/badversion-k32.stoptags -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/fakelump.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-broken.fq.2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-overlap1.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-sweep-reads.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/combine_parts_1.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/real-partition-tiny.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/badversion-k32.tagset -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/normC20k20.ct -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-2.paired.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-graph2.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/100-reads.fq.truncated.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/goodversion-k32.tagset -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/goodversion-k12.ht.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired.fa.1 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/overlap.out -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/100-reads.fq.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-broken2.fq.1 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired.fa.2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-2.fa.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-transcript.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired.fq.2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.even.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-reads.fq.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-broken3.fq.1 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/random-20-a.fq.gz -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed.fq.pe -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-reads.fq.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed.fa.pe -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/biglump-random-20-a.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/old-style-format-w-comments.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read-paired.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-large.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-error-reads.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed.fq.se -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/single-read.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-broken.fq.1 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired-mixed.fa.se -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/paired.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-abund-read.fa -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-sweep-reads.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/casava_18-pe.fq -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test-data/test-empty.fa.bz2 -> build/bdist.linux-x86_64/egg/khmer/tests/test-data\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_counting_single.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_functions.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/tests/test_scripts.py -> build/bdist.linux-x86_64/egg/khmer/tests\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/utils.py -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/_version.py -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/_khmermodule.so -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/__init__.py -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/_khmermodule.cc -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/thread_utils.py -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/kfile.py -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "copying build/lib.linux-x86_64-2.7/khmer/khmer_args.py -> build/bdist.linux-x86_64/egg/khmer\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_script_arguments.py to test_script_arguments.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_subset_graph.py to test_subset_graph.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_hashbits.py to test_hashbits.pyc\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_lump.py to test_lump.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_counting_hash.py to test_counting_hash.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_labelhash.py to test_labelhash.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_graph.py to test_graph.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_read_aligner.py to test_read_aligner.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_version.py to test_version.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_filter.py to test_filter.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_hashbits_obj.py to test_hashbits_obj.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_threaded_sequence_processor.py to test_threaded_sequence_processor.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_read_parsers.py to test_read_parsers.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_hll.py to test_hll.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/khmer_tst_utils.py to khmer_tst_utils.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/__init__.py to __init__.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_sandbox_scripts.py to test_sandbox_scripts.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_counting_single.py to test_counting_single.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_functions.py to test_functions.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/tests/test_scripts.py to test_scripts.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/utils.py to utils.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/_version.py to _version.pyc\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/__init__.py to __init__.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/thread_utils.py to thread_utils.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/kfile.py to kfile.pyc\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/khmer_args.py to khmer_args.pyc\r\n",
        "creating stub loader for khmer/_khmermodule.so\r\n",
        "byte-compiling build/bdist.linux-x86_64/egg/khmer/_khmer.py to _khmer.pyc\r\n",
        "creating build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "installing scripts to build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "running install_scripts\r\n",
        "running build_scripts\r\n",
        "creating build/scripts-2.7\r\n",
        "copying and adjusting scripts/abundance-dist.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/make-initial-stoptags.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/filter-abund.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/filter-abund-single.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/load-into-counting.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/abundance-dist-single.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/extract-partitions.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/partition-graph.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/fastq-to-fasta.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/merge-partitions.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/count-median.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/readstats.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/do-partition.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/find-knots.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/sample-reads-randomly.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/load-graph.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/interleave-reads.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/normalize-by-median.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/extract-long-sequences.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/trim-low-abund.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/count-overlap.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/extract-paired-reads.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/split-paired-reads.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/filter-stoptags.py -> build/scripts-2.7\r\n",
        "copying and adjusting scripts/annotate-partitions.py -> build/scripts-2.7\r\n",
        "changing mode of build/scripts-2.7/abundance-dist.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/make-initial-stoptags.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/filter-abund.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/filter-abund-single.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/load-into-counting.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/abundance-dist-single.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/extract-partitions.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/partition-graph.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/fastq-to-fasta.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/merge-partitions.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/count-median.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/readstats.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/do-partition.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/find-knots.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/sample-reads-randomly.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/load-graph.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/interleave-reads.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/normalize-by-median.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/extract-long-sequences.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/trim-low-abund.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/count-overlap.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/extract-paired-reads.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/split-paired-reads.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/filter-stoptags.py from 644 to 755\r\n",
        "changing mode of build/scripts-2.7/annotate-partitions.py from 644 to 755\r\n",
        "creating build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/abundance-dist.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/make-initial-stoptags.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/filter-abund.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/filter-abund-single.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/load-into-counting.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/abundance-dist-single.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/extract-partitions.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/partition-graph.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/fastq-to-fasta.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/merge-partitions.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/count-median.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/readstats.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/do-partition.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/find-knots.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/sample-reads-randomly.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/load-graph.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/interleave-reads.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/normalize-by-median.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/extract-long-sequences.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/trim-low-abund.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/count-overlap.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/extract-paired-reads.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/split-paired-reads.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/filter-stoptags.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "copying build/scripts-2.7/annotate-partitions.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/abundance-dist.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/make-initial-stoptags.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/filter-abund.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/filter-abund-single.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/load-into-counting.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/abundance-dist-single.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/extract-partitions.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/partition-graph.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/fastq-to-fasta.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/merge-partitions.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/count-median.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/readstats.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/do-partition.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/find-knots.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/sample-reads-randomly.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/load-graph.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/interleave-reads.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/normalize-by-median.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/extract-long-sequences.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/trim-low-abund.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/count-overlap.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/extract-paired-reads.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/split-paired-reads.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/filter-stoptags.py to 755\r\n",
        "changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/annotate-partitions.py to 755\r\n",
        "copying khmer.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "copying khmer.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "copying khmer.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "copying khmer.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "copying khmer.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "copying khmer.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\r\n",
        "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\r\n",
        "creating dist\r\n",
        "creating 'dist/khmer-1.4_rc1_287_gcc8b337-py2.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\r\n",
        "Processing khmer-1.4_rc1_287_gcc8b337-py2.7-linux-x86_64.egg\r\n",
        "creating /usr/local/lib/python2.7/dist-packages/khmer-1.4_rc1_287_gcc8b337-py2.7-linux-x86_64.egg\r\n",
        "Extracting khmer-1.4_rc1_287_gcc8b337-py2.7-linux-x86_64.egg to /usr/local/lib/python2.7/dist-packages\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding khmer 1.4-rc1-287-gcc8b337 to easy-install.pth file\r\n",
        "Installing count-median.py script to /usr/local/bin\r\n",
        "Installing split-paired-reads.py script to /usr/local/bin\r\n",
        "Installing filter-abund-single.py script to /usr/local/bin\r\n",
        "Installing filter-abund.py script to /usr/local/bin\r\n",
        "Installing abundance-dist.py script to /usr/local/bin\r\n",
        "Installing partition-graph.py script to /usr/local/bin\r\n",
        "Installing filter-stoptags.py script to /usr/local/bin\r\n",
        "Installing merge-partitions.py script to /usr/local/bin\r\n",
        "Installing sample-reads-randomly.py script to /usr/local/bin\r\n",
        "Installing normalize-by-median.py script to /usr/local/bin\r\n",
        "Installing extract-partitions.py script to /usr/local/bin\r\n",
        "Installing fastq-to-fasta.py script to /usr/local/bin\r\n",
        "Installing make-initial-stoptags.py script to /usr/local/bin\r\n",
        "Installing count-overlap.py script to /usr/local/bin\r\n",
        "Installing abundance-dist-single.py script to /usr/local/bin\r\n",
        "Installing load-into-counting.py script to /usr/local/bin\r\n",
        "Installing interleave-reads.py script to /usr/local/bin\r\n",
        "Installing load-graph.py script to /usr/local/bin\r\n",
        "Installing trim-low-abund.py script to /usr/local/bin\r\n",
        "Installing readstats.py script to /usr/local/bin\r\n",
        "Installing find-knots.py script to /usr/local/bin\r\n",
        "Installing annotate-partitions.py script to /usr/local/bin\r\n",
        "Installing extract-paired-reads.py script to /usr/local/bin\r\n",
        "Installing extract-long-sequences.py script to /usr/local/bin\r\n",
        "Installing do-partition.py script to /usr/local/bin\r\n",
        "\r\n",
        "Installed /usr/local/lib/python2.7/dist-packages/khmer-1.4_rc1_287_gcc8b337-py2.7-linux-x86_64.egg\r\n",
        "Processing dependencies for khmer==1.4-rc1-287-gcc8b337\r\n",
        "Searching for screed>=0.8\r\n",
        "Reading http://pypi.python.org/simple/screed/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best match: screed 0.8\r\n",
        "Downloading https://pypi.python.org/packages/source/s/screed/screed-0.8.tar.gz#md5=6cd35e0ea096fe19c86b0c2bfb6bb415\r\n",
        "Processing screed-0.8.tar.gz\r\n",
        "Writing /tmp/easy_install-yJO8zG/screed-0.8/setup.cfg\r\n",
        "Running screed-0.8/setup.py -q bdist_egg --dist-dir /tmp/easy_install-yJO8zG/screed-0.8/egg-dist-tmp-lCfsXT\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "zip_safe flag not set; analyzing archive contents...\r\n",
        "screed.tests.test_streaming: module references __file__\r\n",
        "screed.tests.test_dictionary: module references __file__\r\n",
        "screed.tests.test_fasta_recover: module references __file__\r\n",
        "screed.tests.test_fasta: module references __file__\r\n",
        "screed.tests.test_pygr_api: module references __file__\r\n",
        "screed.tests.test_hava_methods: module references __file__\r\n",
        "screed.tests.test_convert: module references __file__\r\n",
        "screed.tests.test_fastq: module references __file__\r\n",
        "screed.tests.test_shell: module references __file__\r\n",
        "screed.tests.test_fastq_recover: module references __file__\r\n",
        "screed.tests.test_open: module references __file__\r\n",
        "screed.tests.__main__: module references __file__\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding screed 0.8 to easy-install.pth file\r\n",
        "\r\n",
        "Installed /usr/local/lib/python2.7/dist-packages/screed-0.8-py2.7.egg\r\n",
        "Searching for bz2file\r\n",
        "Reading http://pypi.python.org/simple/bz2file/\r\n",
        "Best match: bz2file 0.98\r\n",
        "Downloading https://pypi.python.org/packages/source/b/bz2file/bz2file-0.98.tar.gz#md5=27d6f711ae0db6cfd1eb37f95621dfb5\r\n",
        "Processing bz2file-0.98.tar.gz\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing /tmp/easy_install-r0HF9i/bz2file-0.98/setup.cfg\r\n",
        "Running bz2file-0.98/setup.py -q bdist_egg --dist-dir /tmp/easy_install-r0HF9i/bz2file-0.98/egg-dist-tmp-7oE1qV\r\n",
        "zip_safe flag not set; analyzing archive contents...\r\n",
        "Adding bz2file 0.98 to easy-install.pth file\r\n",
        "\r\n",
        "Installed /usr/local/lib/python2.7/dist-packages/bz2file-0.98-py2.7.egg\r\n",
        "Finished processing dependencies for khmer==1.4-rc1-287-gcc8b337\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following script is contained within the *khmer* package and can estimate the total unique number of k-mers in your dataset.  Use cases for this might be a) determining how diverse a metagenome is compared to e.g., a bacterial genome for assembly, b) to compare k-mer diversity among multiple metagenomes, c) exploring the impacts of choice of length k for assembly.\n",
      "\n",
      "Next, to estimate the number unique k-mers in the datasets for multiple k's (17, 21, 25, 29, 33, 37), execute the scripts below.  The script output will identify the unique k-mers but will also save in a report named unique_count. (This takes about 8-10 minutes.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python unique-kmers.py -R unique_count -k 17 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 21 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 25 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 29 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 33 SRR172903.fastq\n",
      "!python unique-kmers.py -R unique_count -k 37 SRR172903.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'unique-kmers.py' in khmer.\r\n",
        "|| You are running khmer version unknown\r\n",
        "|| You are also using screed version 0.8\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. http://dx.doi.org/10.6084/m9.figshare.979190\r\n",
        "||   * A. D\u00f6ring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\r\n",
        "||   * Irber and Brown, unpublished\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimated number of unique k-mers: 92357359\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'unique-kmers.py' in khmer.\r\n",
        "|| You are running khmer version unknown\r\n",
        "|| You are also using screed version 0.8\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. http://dx.doi.org/10.6084/m9.figshare.979190\r\n",
        "||   * A. D\u00f6ring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\r\n",
        "||   * Irber and Brown, unpublished\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimated number of unique k-mers: 107443503\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'unique-kmers.py' in khmer.\r\n",
        "|| You are running khmer version unknown\r\n",
        "|| You are also using screed version 0.8\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. http://dx.doi.org/10.6084/m9.figshare.979190\r\n",
        "||   * A. D\u00f6ring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\r\n",
        "||   * Irber and Brown, unpublished\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimated number of unique k-mers: 115917051\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'unique-kmers.py' in khmer.\r\n",
        "|| You are running khmer version unknown\r\n",
        "|| You are also using screed version 0.8\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. http://dx.doi.org/10.6084/m9.figshare.979190\r\n",
        "||   * A. D\u00f6ring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\r\n",
        "||   * Irber and Brown, unpublished\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimated number of unique k-mers: 119779083\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'unique-kmers.py' in khmer.\r\n",
        "|| You are running khmer version unknown\r\n",
        "|| You are also using screed version 0.8\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. http://dx.doi.org/10.6084/m9.figshare.979190\r\n",
        "||   * A. D\u00f6ring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\r\n",
        "||   * Irber and Brown, unpublished\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimated number of unique k-mers: 123079072\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "|| This is the script 'unique-kmers.py' in khmer.\r\n",
        "|| You are running khmer version unknown\r\n",
        "|| You are also using screed version 0.8\r\n",
        "||\r\n",
        "|| If you use this script in a publication, please cite EACH of the following:\r\n",
        "||\r\n",
        "||   * MR Crusoe et al., 2014. http://dx.doi.org/10.6084/m9.figshare.979190\r\n",
        "||   * A. D\u00f6ring et al. http://dx.doi.org:80/10.1186/1471-2105-9-11\r\n",
        "||   * Irber and Brown, unpublished\r\n",
        "||\r\n",
        "|| Please see http://khmer.readthedocs.org/en/latest/citations.html for details.\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Estimated number of unique k-mers: 121510649\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that this file now has in the first column the k-mer length and in the second column the estimated number of words of length k in the metagenomes. If you had multiple genomes, you could compare diversity of e.g., the total number of k-mers across datasets.  To view the results of the file, you can use the concatentate program/command \"cat\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat unique_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "17 92357359\r\n",
        "21 107443503\r\n",
        "25 115917051\r\n",
        "29 119779083\r\n",
        "33 123079072\r\n",
        "37 121510649"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Getting a sequence coverage profile:  What genes are present in my metagenome?\n",
      "\n",
      "\n",
      "Most metagenomic analysis require one to estimate the abundance of reference genes (e.g., orginating from genomes or one's own metagenomic assembly).  This tutorial will cover both cases where references are available or unavailable (requiring de novo assembly).  \n",
      "\n",
      "### Case I - Reference genomes available.  \n",
      "\n",
      "For the HMP mock metagenome, the HMP has sequenced the genomes of the isolates used for this simulated dataset.  The list of these genomes can be obtained on the HMP website, and we provide it here in a Github repository, a tool used for collaboratively sharing data and code.  The command below will download data for this tutorial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ncbi_acc.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NC_005008.1\r\n",
        "NC_005007.1\r\n",
        "NC_005003.1\r\n",
        "NC_005006.1\r\n",
        "NC_005004.1\r\n",
        "NC_009084.1\r\n",
        "NC_005005.1\r\n",
        "NC_000958.1\r\n",
        "NC_000959.1\r\n",
        "NC_009083.1\r\n",
        "NC_001264.1\r\n",
        "NC_001263.1\r\n",
        "NC_004461.1\r\n",
        "NC_009008.1\r\n",
        "NC_010079.1\r\n",
        "NC_007490.1\r\n",
        "NC_009007.1\r\n",
        "NC_007489.1\r\n",
        "NC_004350.1\r\n",
        "NC_007488.1\r\n",
        "NC_007493.1\r\n",
        "NC_007494.1\r\n",
        "NC_009085.1\r\n",
        "NC_009515.1\r\n",
        "NC_009614.1\r\n",
        "NC_000915.1\r\n",
        "NC_003028.3\r\n",
        "NC_000913.2\r\n",
        "NC_006085.1\r\n",
        "NC_003112.2\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following command downloads all the genomes for each ID in the above list into a directory called \"genomes\".  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python fetch-genomes-fasta.py ncbi_acc.txt genomes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_005008.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_005007.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_005003.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_005006.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_005004.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009084.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_005005.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_000958.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_000959.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009083.1...Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_001264.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_001263.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_004461.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009008.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_010079.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_007490.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009007.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_007489.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_004350.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_007488.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_007493.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_007494.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009085.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009515.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_009614.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_000915.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_003028.3..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_000913.2..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_006085.1..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fetching NC_003112.2..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Estimating presence of metagenome in assembled contigs\n",
      "\n",
      "To estimate the representation of reference genes or genomes in your metagenome, you can align reads to references using read mapping software (e.g., Bowtie2, BWA, etc.).  In this tutorial, we will use Bowtie2 which we will install on this server.  We will then be  mapping the metagenome to a single reference genome (that we downloaded above). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wget http://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip\n",
      "!unzip bowtie2-2.2.5-linux-x86_64.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--2015-04-20 15:42:48--  http://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip\r\n",
        "Resolving sourceforge.net (sourceforge.net)... 216.34.181.60\r\n",
        "Connecting to sourceforge.net (sourceforge.net)|216.34.181.60|:80... connected.\r\n",
        "HTTP request sent, awaiting response... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "302 Found\r\n",
        "Location: http://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip/download [following]\r\n",
        "--2015-04-20 15:42:48--  http://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip/download\r\n",
        "Connecting to sourceforge.net (sourceforge.net)|216.34.181.60|:80... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "connected.\r\n",
        "HTTP request sent, awaiting response... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "302 Found\r\n",
        "Location: http://downloads.sourceforge.net/project/bowtie-bio/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip?r=&ts=1429544568&use_mirror=hivelocity [following]\r\n",
        "--2015-04-20 15:42:48--  http://downloads.sourceforge.net/project/bowtie-bio/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip?r=&ts=1429544568&use_mirror=hivelocity\r\n",
        "Resolving downloads.sourceforge.net (downloads.sourceforge.net)... 216.34.181.59\r\n",
        "Connecting to downloads.sourceforge.net (downloads.sourceforge.net)|216.34.181.59|:80... connected.\r\n",
        "HTTP request sent, awaiting response... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "302 Found\r\n",
        "Location: http://hivelocity.dl.sourceforge.net/project/bowtie-bio/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip [following]\r\n",
        "--2015-04-20 15:42:48--  http://hivelocity.dl.sourceforge.net/project/bowtie-bio/bowtie2/2.2.5/bowtie2-2.2.5-linux-x86_64.zip\r\n",
        "Resolving hivelocity.dl.sourceforge.net (hivelocity.dl.sourceforge.net)... 74.50.101.106\r\n",
        "Connecting to hivelocity.dl.sourceforge.net (hivelocity.dl.sourceforge.net)|74.50.101.106|:80... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "connected.\r\n",
        "HTTP request sent, awaiting response... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200 OK\r\n",
        "Length: 26413746 (25M) [application/octet-stream]\r\n",
        "Saving to: \u2018bowtie2-2.2.5-linux-x86_64.zip\u2019\r\n",
        "\r\n",
        "\r",
        " 0% [                                       ] 0           --.-K/s              "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 3% [>                                      ] 803,375     3.83MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "13% [====>                                  ] 3,580,639   8.54MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "30% [==========>                            ] 7,998,487   11.9MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [================>                      ] 12,190,447  13.8MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "68% [=========================>             ] 18,088,151  16.6MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "81% [==============================>        ] 21,503,487  16.1MB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100%[======================================>] 26,413,746  17.2MB/s   in 1.5s   \r\n",
        "\r\n",
        "2015-04-20 15:42:50 (17.2 MB/s) - \u2018bowtie2-2.2.5-linux-x86_64.zip\u2019 saved [26413746/26413746]\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!unzip bowtie2-2.2.5-linux-x86_64.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Archive:  bowtie2-2.2.5-linux-x86_64.zip\r\n",
        "   creating: bowtie2-2.2.5/\r\n",
        "  inflating: bowtie2-2.2.5/AUTHORS   \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2   \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-align-l  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-align-l-debug  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-align-s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-align-s-debug  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-build  \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-build-l  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-build-l-debug  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-build-s  \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-build-s-debug  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-inspect  \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-inspect-l  \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-inspect-l-debug  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-inspect-s  \r\n",
        "  inflating: bowtie2-2.2.5/bowtie2-inspect-s-debug  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "   creating: bowtie2-2.2.5/doc/\r\n",
        "  inflating: bowtie2-2.2.5/doc/manual.html  \r\n",
        "  inflating: bowtie2-2.2.5/doc/README  \r\n",
        "  inflating: bowtie2-2.2.5/doc/style.css  \r\n",
        "   creating: bowtie2-2.2.5/example/\r\n",
        "   creating: bowtie2-2.2.5/example/index/\r\n",
        "  inflating: bowtie2-2.2.5/example/index/lambda_virus.1.bt2  \r\n",
        "  inflating: bowtie2-2.2.5/example/index/lambda_virus.2.bt2  \r\n",
        "  inflating: bowtie2-2.2.5/example/index/lambda_virus.3.bt2  \r\n",
        "  inflating: bowtie2-2.2.5/example/index/lambda_virus.4.bt2  \r\n",
        "  inflating: bowtie2-2.2.5/example/index/lambda_virus.rev.1.bt2  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/example/index/lambda_virus.rev.2.bt2  \r\n",
        "   creating: bowtie2-2.2.5/example/reads/\r\n",
        "  inflating: bowtie2-2.2.5/example/reads/longreads.fq  \r\n",
        "  inflating: bowtie2-2.2.5/example/reads/reads_1.fq  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "  inflating: bowtie2-2.2.5/example/reads/reads_2.fq  \r\n",
        "  inflating: bowtie2-2.2.5/example/reads/simulate.pl  \r\n",
        "   creating: bowtie2-2.2.5/example/reference/\r\n",
        "  inflating: bowtie2-2.2.5/example/reference/lambda_virus.fa  \r\n",
        "  inflating: bowtie2-2.2.5/LICENSE   \r\n",
        "  inflating: bowtie2-2.2.5/MANUAL    \r\n",
        "  inflating: bowtie2-2.2.5/MANUAL.markdown  \r\n",
        "  inflating: bowtie2-2.2.5/NEWS      \r\n",
        "   creating: bowtie2-2.2.5/scripts/\r\n",
        "  inflating: bowtie2-2.2.5/scripts/convert_quals.pl  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/debug_wrapper.pl  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/gen_2b_occ_lookup.pl  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/gen_occ_lookup.pl  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/gen_solqual_lookup.pl  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/infer_fraglen.pl  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_a_thaliana_tair.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_b_taurus_UMD3.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_canFam2.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_c_elegans.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_d_melanogaster.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_e_coli.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_hg18.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_hg19.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_h_sapiens_ncbi36.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_h_sapiens_ncbi37.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_mm10.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_mm9.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_m_musculus_ncbi37.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_rn4.sh  \r\n",
        "  inflating: bowtie2-2.2.5/scripts/make_s_cerevisiae.sh  \r\n",
        "  inflating: bowtie2-2.2.5/TUTORIAL  \r\n",
        " extracting: bowtie2-2.2.5/VERSION   \r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I've written a script that will automatically map a set of reads to a given reference and output a file containing the number of reads that are mapped to a given reference.  To use this script, we'll also need to install samtools.  A samfile is a super compressed file that efficiently stores mapped information from mappers.  Samtools helps us interact with this file."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "!apt-get install samtools"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To map reads to a reference, we have provided an easy to use program.  The steps the program performs are as follows:\n",
      "\n",
      "* Index your reference genome,\n",
      "* Map reads to your index genome (with default bowtie parameters),\n",
      "* Use Samtools to estimate the number of reads mapped, number of reads unmapped, and provide a tab delimited file with each line consisting of reference sequence name, sequence length, # mapped reads and # unmapped reads.\n",
      "\n",
      "This takes about 8-10 minutes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash bowtie.sh genomes/NC_000913.2.fa SRR172903.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reference is genomes/NC_000913.2.fa\r\n",
        "Reads are SRR172903.fastq\r\n",
        "Settings:\r\n",
        "  Output files: \"genomes/NC_000913.2.fa-bowtie-index.*.bt2\"\r\n",
        "  Line rate: 6 (line is 64 bytes)\r\n",
        "  Lines per side: 1 (side is 64 bytes)\r\n",
        "  Offset rate: 4 (one in 16)\r\n",
        "  FTable chars: 10\r\n",
        "  Strings: unpacked\r\n",
        "  Max bucket size: default\r\n",
        "  Max bucket size, sqrt multiplier: default\r\n",
        "  Max bucket size, len divisor: 4\r\n",
        "  Difference-cover sample period: 1024\r\n",
        "  Endianness: little\r\n",
        "  Actual local endianness: little\r\n",
        "  Sanity checking: disabled\r\n",
        "  Assertions: disabled\r\n",
        "  Random seed: 0\r\n",
        "  Sizeofs: void*:8, int:4, long:8, size_t:8\r\n",
        "Input files DNA, FASTA:\r\n",
        "  genomes/NC_000913.2.fa\r\n",
        "Building a SMALL index\r\n",
        "Reading reference sizes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time reading reference sizes: 00:00:00\r\n",
        "Calculating joined length\r\n",
        "Writing header\r\n",
        "Reserving space for joined string\r\n",
        "Joining reference sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time to join reference sequences: 00:00:00\r\n",
        "bmax according to bmaxDivN setting: 1159918\r\n",
        "Using parameters --bmax 869939 --dcv 1024\r\n",
        "  Doing ahead-of-time memory usage test\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Passed!  Constructing with these parameters: --bmax 869939 --dcv 1024\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Constructing suffix-array element generator\r\n",
        "Building DifferenceCoverSample\r\n",
        "  Building sPrime\r\n",
        "  Building sPrimeOrder\r\n",
        "  V-Sorting samples\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  V-Sorting samples time: 00:00:00\r\n",
        "  Allocating rank array\r\n",
        "  Ranking v-sort output\r\n",
        "  Ranking v-sort output time: 00:00:00\r\n",
        "  Invoking Larsson-Sadakane on ranks\r\n",
        "  Invoking Larsson-Sadakane on ranks time: 00:00:00\r\n",
        "  Sanity-checking and returning\r\n",
        "Building samples\r\n",
        "Reserving space for 12 sample suffixes\r\n",
        "Generating random suffixes\r\n",
        "QSorting 12 sample offsets, eliminating duplicates\r\n",
        "QSorting sample offsets, eliminating duplicates time: 00:00:00\r\n",
        "Multikey QSorting 12 samples\r\n",
        "  (Using difference cover)\r\n",
        "  Multikey QSorting samples time: 00:00:00\r\n",
        "Calculating bucket sizes\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n",
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:00\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 2, merged 6; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n",
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n",
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:01\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 1, merged 1; iterating...\r\n",
        "  Binary sorting into buckets\r\n",
        "  10%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n",
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:00\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Avg bucket size: 579958 (target: 869938)\r\n",
        "Converting suffix-array elements to index image\r\n",
        "Allocating ftab, absorbFtab\r\n",
        "Entering Ebwt loop\r\n",
        "Getting block 1 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 566788\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 566789\r\n",
        "Getting block 2 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 564637\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 564638\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 3 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 645098\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 645099\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 4 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 234151\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:01\r\n",
        "Returning block of 234152\r\n",
        "Getting block 5 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 643592\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 643593\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 6 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 711613\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 711614\r\n",
        "Getting block 7 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 574603\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 574604\r\n",
        "Getting block 8 of 8\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 699186\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 699187\r\n",
        "Exited Ebwt loop\r\n",
        "fchr[A]: 0\r\n",
        "fchr[C]: 1142228\r\n",
        "fchr[G]: 2321782\r\n",
        "fchr[T]: 3498705\r\n",
        "fchr[$]: 4639675\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exiting Ebwt::buildToDisk()\r\n",
        "Returning from initFromVector\r\n",
        "Wrote 5741113 bytes to primary EBWT file: genomes/NC_000913.2.fa-bowtie-index.1.bt2\r\n",
        "Wrote 1159924 bytes to secondary EBWT file: genomes/NC_000913.2.fa-bowtie-index.2.bt2\r\n",
        "Re-opening _in1 and _in2 as input streams\r\n",
        "Returning from Ebwt constructor\r\n",
        "Headers:\r\n",
        "    len: 4639675\r\n",
        "    bwtLen: 4639676\r\n",
        "    sz: 1159919\r\n",
        "    bwtSz: 1159919\r\n",
        "    lineRate: 6\r\n",
        "    offRate: 4\r\n",
        "    offMask: 0xfffffff0\r\n",
        "    ftabChars: 10\r\n",
        "    eftabLen: 20\r\n",
        "    eftabSz: 80\r\n",
        "    ftabLen: 1048577\r\n",
        "    ftabSz: 4194308\r\n",
        "    offsLen: 289980\r\n",
        "    offsSz: 1159920\r\n",
        "    lineSz: 64\r\n",
        "    sideSz: 64\r\n",
        "    sideBwtSz: 48\r\n",
        "    sideBwtLen: 192\r\n",
        "    numSides: 24165\r\n",
        "    numLines: 24165\r\n",
        "    ebwtTotLen: 1546560\r\n",
        "    ebwtTotSz: 1546560\r\n",
        "    color: 0\r\n",
        "    reverse: 0\r\n",
        "Total time for call to driver() for forward index: 00:00:02\r\n",
        "Reading reference sizes\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time reading reference sizes: 00:00:00\r\n",
        "Calculating joined length\r\n",
        "Writing header\r\n",
        "Reserving space for joined string\r\n",
        "Joining reference sequences\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Time to join reference sequences: 00:00:01\r\n",
        "  Time to reverse reference sequence: 00:00:00\r\n",
        "bmax according to bmaxDivN setting: 1159918\r\n",
        "Using parameters --bmax 869939 --dcv 1024\r\n",
        "  Doing ahead-of-time memory usage test\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Passed!  Constructing with these parameters: --bmax 869939 --dcv 1024\r\n",
        "Constructing suffix-array element generator\r\n",
        "Building DifferenceCoverSample\r\n",
        "  Building sPrime\r\n",
        "  Building sPrimeOrder\r\n",
        "  V-Sorting samples\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  V-Sorting samples time: 00:00:00\r\n",
        "  Allocating rank array\r\n",
        "  Ranking v-sort output\r\n",
        "  Ranking v-sort output time: 00:00:00\r\n",
        "  Invoking Larsson-Sadakane on ranks\r\n",
        "  Invoking Larsson-Sadakane on ranks time: 00:00:00\r\n",
        "  Sanity-checking and returning\r\n",
        "Building samples\r\n",
        "Reserving space for 12 sample suffixes\r\n",
        "Generating random suffixes\r\n",
        "QSorting 12 sample offsets, eliminating duplicates\r\n",
        "QSorting sample offsets, eliminating duplicates time: 00:00:00\r\n",
        "Multikey QSorting 12 samples\r\n",
        "  (Using difference cover)\r\n",
        "  Multikey QSorting samples time: 00:00:00\r\n",
        "Calculating bucket sizes\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n",
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:00\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Split 2, merged 6; iterating...\r\n",
        "  Binary sorting into buckets\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n",
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  90%\r\n",
        "  100%\r\n",
        "  Binary sorting into buckets time: 00:00:00\r\n",
        "Splitting and merging\r\n",
        "  Splitting and merging time: 00:00:00\r\n",
        "Avg bucket size: 662810 (target: 869938)\r\n",
        "Converting suffix-array elements to index image\r\n",
        "Allocating ftab, absorbFtab\r\n",
        "Entering Ebwt loop\r\n",
        "Getting block 1 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 504667\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 504668\r\n",
        "Getting block 2 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 574835\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 574836\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 3 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 367744\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:01\r\n",
        "Returning block of 367745\r\n",
        "Getting block 4 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 868288\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 868289\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 5 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 852473\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 852474\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 6 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n",
        "  80%\r\n",
        "  90%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 759657\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:00\r\n",
        "Returning block of 759658\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting block 7 of 7\r\n",
        "  Reserving size (869939) for bucket\r\n",
        "  Calculating Z arrays\r\n",
        "  Calculating Z arrays time: 00:00:00\r\n",
        "  Entering block accumulator loop:\r\n",
        "  10%\r\n",
        "  20%\r\n",
        "  30%\r\n",
        "  40%\r\n",
        "  50%\r\n",
        "  60%\r\n",
        "  70%\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  80%\r\n",
        "  90%\r\n",
        "  100%\r\n",
        "  Block accumulator loop time: 00:00:00\r\n",
        "  Sorting block of length 712005\r\n",
        "  (Using difference cover)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Sorting block time: 00:00:01\r\n",
        "Returning block of 712006\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Exited Ebwt loop\r\n",
        "fchr[A]: 0\r\n",
        "fchr[C]: 1142228\r\n",
        "fchr[G]: 2321782\r\n",
        "fchr[T]: 3498705\r\n",
        "fchr[$]: 4639675\r\n",
        "Exiting Ebwt::buildToDisk()\r\n",
        "Returning from initFromVector\r\n",
        "Wrote 5741113 bytes to primary EBWT file: genomes/NC_000913.2.fa-bowtie-index.rev.1.bt2\r\n",
        "Wrote 1159924 bytes to secondary EBWT file: genomes/NC_000913.2.fa-bowtie-index.rev.2.bt2\r\n",
        "Re-opening _in1 and _in2 as input streams\r\n",
        "Returning from Ebwt constructor\r\n",
        "Headers:\r\n",
        "    len: 4639675\r\n",
        "    bwtLen: 4639676\r\n",
        "    sz: 1159919\r\n",
        "    bwtSz: 1159919\r\n",
        "    lineRate: 6\r\n",
        "    offRate: 4\r\n",
        "    offMask: 0xfffffff0\r\n",
        "    ftabChars: 10\r\n",
        "    eftabLen: 20\r\n",
        "    eftabSz: 80\r\n",
        "    ftabLen: 1048577\r\n",
        "    ftabSz: 4194308\r\n",
        "    offsLen: 289980\r\n",
        "    offsSz: 1159920\r\n",
        "    lineSz: 64\r\n",
        "    sideSz: 64\r\n",
        "    sideBwtSz: 48\r\n",
        "    sideBwtLen: 192\r\n",
        "    numSides: 24165\r\n",
        "    numLines: 24165\r\n",
        "    ebwtTotLen: 1546560\r\n",
        "    ebwtTotSz: 1546560\r\n",
        "    color: 0\r\n",
        "    reverse: 1\r\n",
        "Total time for backward call to driver() for mirror index: 00:00:03\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7932819 reads; of these:\r\n",
        "  7932819 (100.00%) were unpaired; of these:\r\n",
        "    7358331 (92.76%) aligned 0 times\r\n",
        "    553695 (6.98%) aligned exactly 1 time\r\n",
        "    20793 (0.26%) aligned >1 times\r\n",
        "7.24% overall alignment rate\r\n",
        "[samopen] SAM header is present: 1 sequences.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[bam_sort_core] merging from 4 files...\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can look at the total number of reads mapped and unmapped from our metagenome to the genome NC_000913.2.  We can also get a file that shows the reference sequence name (first column), reference sequence length (second column), # mapped reads (third column) and # unmapped reads (last column).  The other columns contain information that samtools can use for other queries, you can read about samtools here, http://samtools.sourceforge.net/samtools.shtml."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads-mapped.count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "574488\r\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads-unmapped.count.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7358331\r\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat reads.by.contigs.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gi|49175990|ref|NC_000913.2|\t4639675\t574488\t0\r\n",
        "*\t0\t0\t7358331\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want a challenge, you can try mapping the metagenome to all reference genomes provided in the genome folder.  To do so, try concatentating all genomes into one file (using this command:  \"cat genomes/*fa >> all-genomes.fa\") and running the program on all-genomes.fa instead of NC_000913.2.fa."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "### Case II - *De novo* assembly of reference genes.\n",
      "\n",
      "\n",
      "###  Assembly of the HMP mock metagenome\n",
      "\n",
      "Assembly is the process of merging overlapping metagenomic reads from *hopefully* the same genome into a longer, continguous sequence (most commonly called a contig).  It is advantageous is that it provides longer lengths for analyzing what the sequence represents, reduces the dataset size for analysis, and provides references that are not dependent on previous knowledge.  \n",
      "\n",
      "The choice of what assembler to use is not an easy one and is a subject of debate (see http://assemblathon.org).  It is most important to remember that an assembly is a *hypothesized* consensus representation of your dataset.  The assembly itself is an initial step that needs to be followed by an evaluation of its accuracy and usefulness.  For most assemblers, you will need only two things:  Metagenomic reads which you are comfortable with their quality (e.g., quality-score trimmed, adapters removed) and assembly software.  For this tutorial, we will be completing the assembly with an assembler published in 2014 called Megahit (MEGAHIT: An ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph, https://github.com/voutcn/megahit).  Sharpton's review (xxxx) also reviews quite nicely some of the many assembly programs and approaches for metagenomic assembly.  \n",
      "\n",
      "To reduce the memory that is needed, it is often advantageeous to normalize the distribution of k-mers in a metagenome.  Removing extraneous information not needed for assembly also removes reads that may contain errors and may improve assembly (cite diginorm paper).  These scripts and tutorials are available at http://ged.msu.edu/angus/diginorm-2012/tutorial.html.\n",
      "\n",
      "For this tutorial, we will assemble our metagenome with the Megathit assembler so first we have to install it.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!bash install-megahit.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Too many arguments.\r\n",
        "\r\n",
        "usage: git clone [options] [--] <repo> [<dir>]\r\n",
        "\r\n",
        "    -v, --verbose         be more verbose\r\n",
        "    -q, --quiet           be more quiet\r\n",
        "    --progress            force progress reporting\r\n",
        "    -n, --no-checkout     don't create a checkout\r\n",
        "    --bare                create a bare repository\r\n",
        "    --mirror              create a mirror repository (implies bare)\r\n",
        "    -l, --local           to clone from a local repository\r\n",
        "    --no-hardlinks        don't use local hardlinks, always copy\r\n",
        "    -s, --shared          setup as shared repository\r\n",
        "    --recursive           initialize submodules in the clone\r\n",
        "    --recurse-submodules  initialize submodules in the clone\r\n",
        "    --template <template-directory>\r\n",
        "                          directory from which templates will be used\r\n",
        "    --reference <repo>    reference repository\r\n",
        "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\r\n",
        "    -b, --branch <branch>\r\n",
        "                          checkout <branch> instead of the remote's HEAD\r\n",
        "    -u, --upload-pack <path>\r\n",
        "                          path to git-upload-pack on the remote\r\n",
        "    --depth <depth>       create a shallow clone of that depth\r\n",
        "    --single-branch       clone only one branch, HEAD or --branch\r\n",
        "    --separate-git-dir <gitdir>\r\n",
        "                          separate git dir from working tree\r\n",
        "    -c, --config <key=value>\r\n",
        "                          set config inside the new repository\r\n",
        "\r\n",
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -c succinct_dbg.cpp -o succinct_dbg.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "succinct_dbg.cpp: In member function \u2018void SuccinctDBG::LoadFromFile(const char*)\u2019:\r\n",
        "succinct_dbg.cpp:338:34: warning: ignoring return value of \u2018int fscanf(FILE*, const char*, ...)\u2019, declared with attribute warn_unused_result [-Wunused-result]\r\n",
        "     fscanf(f_file, \"%d\", &kmer_k);\r\n",
        "                                  ^\r\n",
        "succinct_dbg.cpp:339:45: warning: ignoring return value of \u2018int fscanf(FILE*, const char*, ...)\u2019, declared with attribute warn_unused_result [-Wunused-result]\r\n",
        "     fscanf(f_file, \"%u\", &num_dollar_nodes_);\r\n",
        "                                             ^\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -c rank_and_select.cpp -o rank_and_select.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rank_and_select.cpp: In constructor \u2018RankAndSelect4Bits::RankAndSelect4Bits()\u2019:\r\n",
        "rank_and_select.cpp:34:31: warning: array subscript is above array bounds [-Warray-bounds]\r\n",
        "         popcount_char_xorer_[i] = ~popcount_char_xorer_[i];\r\n",
        "                               ^\r\n",
        "rank_and_select.cpp:34:31: warning: array subscript is above array bounds [-Warray-bounds]\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -c assembly_algorithms.cpp -o assembly_algorithms.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -c branch_group.cpp -o branch_group.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -c options_description.cpp -o options_description.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -c unitig_graph.cpp -o unitig_graph.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt assembler.cpp rank_and_select.o succinct_dbg.o assembly_algorithms.o branch_group.o options_description.o unitig_graph.o -lz -o megahit_assemble\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -D KMER_NUM_UINT64=2 iterate_edges.cpp options_description.o -lz -o megahit_iter_k61\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -D KMER_NUM_UINT64=3 iterate_edges.cpp options_description.o -lz -o megahit_iter_k92\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -D KMER_NUM_UINT64=4 iterate_edges.cpp options_description.o -lz -o megahit_iter_k124\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -D DISABLE_GPU -c cx1_functions.cpp -o .cx1_functions_cpu.o\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "g++ -O3 -Wall -funroll-loops -fprefetch-loop-arrays -fopenmp -std=c++0x -static-libgcc -lm -mpopcnt -D DISABLE_GPU sdbg_builder.cpp .cx1_functions_cpu.o options_description.o -lz -o sdbg_builder_cpu\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "chmod +x ./megahit\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This assembly will take about 15 minutes and will save the assembly to a folder names \"megahit_assembly\".  You can read about the parameters to this program, such as --memory that specifies the maximum memory that can be used on the megahit software repo, https://github.com/voutcn/megahit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!megahit/megahit --memory 10e9 -l 250 --k-max 81 -r SRR172903.fastq --cpu-only -o megahit_assembly"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MEGAHIT v0.2.1\r\n",
        "[Mon Apr 20 16:13:00 2015] Start assembly. Number of CPU threads 4.\r\n",
        "[Mon Apr 20 16:13:00 2015] Extracting solid (k+1)-mers for k = 21\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:14:35 2015] Building graph for k = 21\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:15:07 2015] Assembling contigs from SdBG for k = 21\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:16:35 2015] Extracting iterative edges from k = 21 to 31\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:17:29 2015] Building graph for k = 31\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:18:14 2015] Assembling contigs from SdBG for k = 31\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:19:18 2015] Extracting iterative edges from k = 31 to 41\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:19:39 2015] Building graph for k = 41\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:20:23 2015] Assembling contigs from SdBG for k = 41\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:21:07 2015] Extracting iterative edges from k = 41 to 51\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:21:15 2015] Building graph for k = 51\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:21:46 2015] Assembling contigs from SdBG for k = 51\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:22:16 2015] Extracting iterative edges from k = 51 to 61\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:22:18 2015] Building graph for k = 61\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:22:37 2015] Assembling contigs from SdBG for k = 61\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:22:56 2015] Extracting iterative edges from k = 61 to 71\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:22:57 2015] Building graph for k = 71\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:23:12 2015] Assembling contigs from SdBG for k = 71\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:23:27 2015] Extracting iterative edges from k = 71 to 81\r\n",
        "[Mon Apr 20 16:23:27 2015] Building graph for k = 81\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:23:28 2015] Assembling contigs from SdBG for k = 81\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:23:28 2015] Merging to output final contigs.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Mon Apr 20 16:23:28 2015] ALL DONE.\r\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To take a look at the assembly, let's run the khmer assembly summary program on it, the final contigs are in megahit_assembly/final.contigs.fa.  Let's get statistics on all contigs greater than or equal to 200 bp."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python khmer/sandbox/assemstats3.py 200 megahit_assembly/final.contigs.fa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "** cutoff: 200\r\n",
        "N\tsum\tmax\tfilename\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8189\t18754162\t149694\tmegahit_assembly/final.contigs.fa\r\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}